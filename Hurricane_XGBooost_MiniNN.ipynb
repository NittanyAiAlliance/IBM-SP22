{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hurricane_XGBooost_MiniNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IPCpXVDss0lg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Pre-Processing"
      ],
      "metadata": {
        "id": "-vPC_7hAvrBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_AMM_JJASOM_mean = pd.read_table('./Data/AMM_JJASOM_mean_1950-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_AMM_JJASOM_mean = df_AMM_JJASOM_mean.rename(columns={0: \"Year\", 1:\"AMM_JJASOM_mean\"}).copy()\n",
        "df_AMM_JJASOM_mean"
      ],
      "metadata": {
        "id": "4zOlpGkYuUtk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "94a463e5-0bc7-4f5c-9000-32958220b8b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6381d269-b352-471b-a29f-1e35cba26ac0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>AMM_JJASOM_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1950</td>\n",
              "      <td>1.016667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1951</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1952</td>\n",
              "      <td>2.373333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1953</td>\n",
              "      <td>1.163333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954</td>\n",
              "      <td>-0.635000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>2016</td>\n",
              "      <td>1.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>2017</td>\n",
              "      <td>2.618333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>2018</td>\n",
              "      <td>-2.171667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>2019</td>\n",
              "      <td>0.566667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>2020</td>\n",
              "      <td>1.467830</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6381d269-b352-471b-a29f-1e35cba26ac0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6381d269-b352-471b-a29f-1e35cba26ac0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6381d269-b352-471b-a29f-1e35cba26ac0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Year  AMM_JJASOM_mean\n",
              "0   1950         1.016667\n",
              "1   1951         0.916667\n",
              "2   1952         2.373333\n",
              "3   1953         1.163333\n",
              "4   1954        -0.635000\n",
              "..   ...              ...\n",
              "66  2016         1.530000\n",
              "67  2017         2.618333\n",
              "68  2018        -2.171667\n",
              "69  2019         0.566667\n",
              "70  2020         1.467830\n",
              "\n",
              "[71 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ERSSTv5_ASO_MDRRelative = pd.read_table('./Data/ERSSTv5_ASO_MDRRelative_SST_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_ERSSTv5_ASO_MDRRelative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Qog9C0FUgYik",
        "outputId": "b3115823-66ba-45aa-dbbf-f03bd21fbe14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a1791a55-6b4d-489f-91d9-a2e3314afa35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.239469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.396031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.743195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.021984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.161659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0.082054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0.221386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>-0.232869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>-0.098519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0.183437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1791a55-6b4d-489f-91d9-a2e3314afa35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1791a55-6b4d-489f-91d9-a2e3314afa35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1791a55-6b4d-489f-91d9-a2e3314afa35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0\n",
              "0    0.239469\n",
              "1   -0.396031\n",
              "2   -0.743195\n",
              "3   -0.021984\n",
              "4    0.161659\n",
              "..        ...\n",
              "146  0.082054\n",
              "147  0.221386\n",
              "148 -0.232869\n",
              "149 -0.098519\n",
              "150  0.183437\n",
              "\n",
              "[151 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ERSSTv5_ASO_MDR = pd.read_table('./Data/ERSSTv5_ASO_MDR_SST_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_ERSSTv5_ASO_MDR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "eXmi5UabvctX",
        "outputId": "bf569aa4-c330-451b-ce9e-7ce3e917df0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c74420e7-8b5f-4d5d-8d24-0a28deed465c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27.65656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27.01905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.62783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27.38899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27.44587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>28.36498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>28.43985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>27.93210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>28.12645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>28.35310</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c74420e7-8b5f-4d5d-8d24-0a28deed465c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c74420e7-8b5f-4d5d-8d24-0a28deed465c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c74420e7-8b5f-4d5d-8d24-0a28deed465c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0\n",
              "0    27.65656\n",
              "1    27.01905\n",
              "2    26.62783\n",
              "3    27.38899\n",
              "4    27.44587\n",
              "..        ...\n",
              "146  28.36498\n",
              "147  28.43985\n",
              "148  27.93210\n",
              "149  28.12645\n",
              "150  28.35310\n",
              "\n",
              "[151 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ERSSTv5_ASO_MDR_anomalies = pd.read_table('./Data/ERSSTv5_ASO_MDR_SST_anomalies_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_ERSSTv5_ASO_MDR_anomalies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "x2Qi6l7rhjYD",
        "outputId": "069843b3-3fc7-442e-d454-53df1d978fc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d39b4ca5-6c87-4ee8-b10e-4fa68beb33d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.233739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.871247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.262471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.501313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.444434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0.474681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0.549548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0.041802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0.236148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0.462798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d39b4ca5-6c87-4ee8-b10e-4fa68beb33d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d39b4ca5-6c87-4ee8-b10e-4fa68beb33d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d39b4ca5-6c87-4ee8-b10e-4fa68beb33d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0\n",
              "0   -0.233739\n",
              "1   -0.871247\n",
              "2   -1.262471\n",
              "3   -0.501313\n",
              "4   -0.444434\n",
              "..        ...\n",
              "146  0.474681\n",
              "147  0.549548\n",
              "148  0.041802\n",
              "149  0.236148\n",
              "150  0.462798\n",
              "\n",
              "[151 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ERSSTv5_ASO_MDR_tropics = pd.read_table('./Data/ERSSTv5_ASO_tropics_SST_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_ERSSTv5_ASO_MDR_tropics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "3FKy1MvNh-wo",
        "outputId": "9a62ffcb-4bd3-4a1a-a0e1-21c5ec38fcb6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b8ff4b9e-0e2b-44cd-9cc9-f1dd6a14b90e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25.89209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.89008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25.84602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25.88597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.75921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>26.75793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>26.69346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>26.63997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>26.69997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>26.64466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8ff4b9e-0e2b-44cd-9cc9-f1dd6a14b90e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8ff4b9e-0e2b-44cd-9cc9-f1dd6a14b90e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8ff4b9e-0e2b-44cd-9cc9-f1dd6a14b90e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0\n",
              "0    25.89209\n",
              "1    25.89008\n",
              "2    25.84602\n",
              "3    25.88597\n",
              "4    25.75921\n",
              "..        ...\n",
              "146  26.75793\n",
              "147  26.69346\n",
              "148  26.63997\n",
              "149  26.69997\n",
              "150  26.64466\n",
              "\n",
              "[151 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ERSSTv5_ASO_MDR_tropics_anomalies = pd.read_table('./Data/ERSSTv5_ASO_tropics_SST_anomalies_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_ERSSTv5_ASO_MDR_tropics_anomalies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "s7jfpnzbiJjh",
        "outputId": "8443adfa-9c71-4bb8-e06b-232e32a1795f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c32f7e87-927b-470c-9fc9-5218565f2d8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.473208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.475217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.519276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.479329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.606093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0.392627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0.328162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0.274671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0.334666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0.279361</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c32f7e87-927b-470c-9fc9-5218565f2d8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c32f7e87-927b-470c-9fc9-5218565f2d8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c32f7e87-927b-470c-9fc9-5218565f2d8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0\n",
              "0   -0.473208\n",
              "1   -0.475217\n",
              "2   -0.519276\n",
              "3   -0.479329\n",
              "4   -0.606093\n",
              "..        ...\n",
              "146  0.392627\n",
              "147  0.328162\n",
              "148  0.274671\n",
              "149  0.334666\n",
              "150  0.279361\n",
              "\n",
              "[151 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_HURDAT_TCCounts = pd.read_table('./Data/HURDAT_TCCounts_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_HURDAT_TCCounts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9V8Qwr3cukeB",
        "outputId": "369a730e-7fd6-49a6-ae23-6ff4a88afcdd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c88ec33d-c110-434a-b950-e6a6e8a4581e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1870</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1871</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1872</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1873</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1874</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2016</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2017</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2018</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2019</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>2020</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c88ec33d-c110-434a-b950-e6a6e8a4581e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c88ec33d-c110-434a-b950-e6a6e8a4581e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c88ec33d-c110-434a-b950-e6a6e8a4581e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0   1\n",
              "0    1870  11\n",
              "1    1871   8\n",
              "2    1872   5\n",
              "3    1873   5\n",
              "4    1874   7\n",
              "..    ...  ..\n",
              "146  2016  15\n",
              "147  2017  17\n",
              "148  2018  15\n",
              "149  2019  18\n",
              "150  2020  30\n",
              "\n",
              "[151 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_NAO_DJFM_mean = pd.read_table('./Data/NAO_DJFM_mean_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_NAO_DJFM_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "x_bUsqe5u0ho",
        "outputId": "84aad00f-b5e2-4c36-d728-384b29458533"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-778f80c4-48f7-4256-a8fe-dfd9b1364259\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1870</td>\n",
              "      <td>0.00275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1871</td>\n",
              "      <td>0.05475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1872</td>\n",
              "      <td>0.24850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1873</td>\n",
              "      <td>1.77750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1874</td>\n",
              "      <td>-0.53575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2016</td>\n",
              "      <td>1.17500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2017</td>\n",
              "      <td>0.39925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2018</td>\n",
              "      <td>1.46525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2019</td>\n",
              "      <td>2.22850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>2020</td>\n",
              "      <td>-0.13500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-778f80c4-48f7-4256-a8fe-dfd9b1364259')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-778f80c4-48f7-4256-a8fe-dfd9b1364259 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-778f80c4-48f7-4256-a8fe-dfd9b1364259');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0        1\n",
              "0    1870  0.00275\n",
              "1    1871  0.05475\n",
              "2    1872  0.24850\n",
              "3    1873  1.77750\n",
              "4    1874 -0.53575\n",
              "..    ...      ...\n",
              "146  2016  1.17500\n",
              "147  2017  0.39925\n",
              "148  2018  1.46525\n",
              "149  2019  2.22850\n",
              "150  2020 -0.13500\n",
              "\n",
              "[151 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_NAO_MJ_mean = pd.read_table('./Data/NAO_MJ_mean_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_NAO_MJ_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "lzwqpDhSiyD-",
        "outputId": "16ab7e74-4672-425f-873c-78df4f674b09"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4458c712-fd95-40d6-8255-2a9379584b3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1870</td>\n",
              "      <td>1.0530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1871</td>\n",
              "      <td>-1.9325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1872</td>\n",
              "      <td>-0.1640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1873</td>\n",
              "      <td>-0.0725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1874</td>\n",
              "      <td>-1.3055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2016</td>\n",
              "      <td>-1.0485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2017</td>\n",
              "      <td>-0.0835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2018</td>\n",
              "      <td>0.3060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2019</td>\n",
              "      <td>-0.3895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>2020</td>\n",
              "      <td>-0.8060</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4458c712-fd95-40d6-8255-2a9379584b3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4458c712-fd95-40d6-8255-2a9379584b3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4458c712-fd95-40d6-8255-2a9379584b3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0       1\n",
              "0    1870  1.0530\n",
              "1    1871 -1.9325\n",
              "2    1872 -0.1640\n",
              "3    1873 -0.0725\n",
              "4    1874 -1.3055\n",
              "..    ...     ...\n",
              "146  2016 -1.0485\n",
              "147  2017 -0.0835\n",
              "148  2018  0.3060\n",
              "149  2019 -0.3895\n",
              "150  2020 -0.8060\n",
              "\n",
              "[151 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Nino12_DJF = pd.read_table('./Data/Nino12_DJF_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_Nino12_DJF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "VGUQcf98wjg1",
        "outputId": "a9093609-af7b-43f4-eea3-acd0a9a37951"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5ad102e2-39d1-4a5b-9683-2b17d0918f69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1870</td>\n",
              "      <td>-0.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1871</td>\n",
              "      <td>-1.156667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1872</td>\n",
              "      <td>-1.003333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1873</td>\n",
              "      <td>-1.156667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1874</td>\n",
              "      <td>-0.676667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2016</td>\n",
              "      <td>0.423333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2017</td>\n",
              "      <td>-1.073333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2018</td>\n",
              "      <td>0.706667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2019</td>\n",
              "      <td>-0.113333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>2020</td>\n",
              "      <td>-0.633000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ad102e2-39d1-4a5b-9683-2b17d0918f69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ad102e2-39d1-4a5b-9683-2b17d0918f69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ad102e2-39d1-4a5b-9683-2b17d0918f69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0         1\n",
              "0    1870 -0.850000\n",
              "1    1871 -1.156667\n",
              "2    1872 -1.003333\n",
              "3    1873 -1.156667\n",
              "4    1874 -0.676667\n",
              "..    ...       ...\n",
              "146  2016  0.423333\n",
              "147  2017 -1.073333\n",
              "148  2018  0.706667\n",
              "149  2019 -0.113333\n",
              "150  2020 -0.633000\n",
              "\n",
              "[151 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Nino34_DJF = pd.read_table('./Data/Nino34_DJF_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_Nino34_DJF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tqueJliLi_3y",
        "outputId": "1c3c337f-0c9e-46d0-9907-a988f9fcf54d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c55d3034-2b10-4b87-94a7-ddc7e593ee60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1870</td>\n",
              "      <td>-0.540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1871</td>\n",
              "      <td>-0.640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1872</td>\n",
              "      <td>-0.890000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1873</td>\n",
              "      <td>-0.896667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1874</td>\n",
              "      <td>-0.740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2016</td>\n",
              "      <td>-0.286667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2017</td>\n",
              "      <td>-0.813333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2018</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2019</td>\n",
              "      <td>0.543333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>2020</td>\n",
              "      <td>-0.987000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c55d3034-2b10-4b87-94a7-ddc7e593ee60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c55d3034-2b10-4b87-94a7-ddc7e593ee60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c55d3034-2b10-4b87-94a7-ddc7e593ee60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0         1\n",
              "0    1870 -0.540000\n",
              "1    1871 -0.640000\n",
              "2    1872 -0.890000\n",
              "3    1873 -0.896667\n",
              "4    1874 -0.740000\n",
              "..    ...       ...\n",
              "146  2016 -0.286667\n",
              "147  2017 -0.813333\n",
              "148  2018  0.700000\n",
              "149  2019  0.543333\n",
              "150  2020 -0.987000\n",
              "\n",
              "[151 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Nino3_DJF = pd.read_table('./Data/Nino3_DJF_1870-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_Nino3_DJF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Ik--lQkjjEfl",
        "outputId": "b34ae37e-7afa-4fa9-bf27-b08cec79e139"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b8ac7a0b-1b13-455d-bee4-dd701c838b13\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1870</td>\n",
              "      <td>-0.573333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1871</td>\n",
              "      <td>-0.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1872</td>\n",
              "      <td>-1.046667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1873</td>\n",
              "      <td>-1.276667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1874</td>\n",
              "      <td>-0.793333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2016</td>\n",
              "      <td>-0.056667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2017</td>\n",
              "      <td>-1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2018</td>\n",
              "      <td>0.720000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2019</td>\n",
              "      <td>0.273333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>2020</td>\n",
              "      <td>-0.650000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8ac7a0b-1b13-455d-bee4-dd701c838b13')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8ac7a0b-1b13-455d-bee4-dd701c838b13 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8ac7a0b-1b13-455d-bee4-dd701c838b13');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0         1\n",
              "0    1870 -0.573333\n",
              "1    1871 -0.710000\n",
              "2    1872 -1.046667\n",
              "3    1873 -1.276667\n",
              "4    1874 -0.793333\n",
              "..    ...       ...\n",
              "146  2016 -0.056667\n",
              "147  2017 -1.010000\n",
              "148  2018  0.720000\n",
              "149  2019  0.273333\n",
              "150  2020 -0.650000\n",
              "\n",
              "[151 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_SahelPrecipIndex_JJAS_mean = pd.read_table('./Data/SahelPrecipIndex_JJAS_mean_1901-2017.dat', sep=\"\\s+\", header=None)\n",
        "df_SahelPrecipIndex_JJAS_mean = df_SahelPrecipIndex_JJAS_mean.rename(columns={0: \"Year\", 1:\"SahelPrecipIndex_JJAS_mean\"}).copy()"
      ],
      "metadata": {
        "id": "xF8VRiXjjI-z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_SahelPrecipIndex_JJAS_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "rF-rSDXfjc07",
        "outputId": "71a1b8a5-81ad-4d83-8185-9bb0b64bc6cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-be58437e-ceca-4c75-abf0-652e957d9f74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>SahelPrecipIndex_JJAS_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1901</td>\n",
              "      <td>3.7100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1902</td>\n",
              "      <td>0.1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1903</td>\n",
              "      <td>2.0825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1904</td>\n",
              "      <td>0.9850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1905</td>\n",
              "      <td>2.5625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>2013</td>\n",
              "      <td>0.6425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>2014</td>\n",
              "      <td>0.5050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>2015</td>\n",
              "      <td>3.0375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>2016</td>\n",
              "      <td>2.5250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>2017</td>\n",
              "      <td>1.2625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be58437e-ceca-4c75-abf0-652e957d9f74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be58437e-ceca-4c75-abf0-652e957d9f74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be58437e-ceca-4c75-abf0-652e957d9f74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Year  SahelPrecipIndex_JJAS_mean\n",
              "0    1901                      3.7100\n",
              "1    1902                      0.1200\n",
              "2    1903                      2.0825\n",
              "3    1904                      0.9850\n",
              "4    1905                      2.5625\n",
              "..    ...                         ...\n",
              "112  2013                      0.6425\n",
              "113  2014                      0.5050\n",
              "114  2015                      3.0375\n",
              "115  2016                      2.5250\n",
              "116  2017                      1.2625\n",
              "\n",
              "[117 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_VK08_TCCount = pd.read_table('./Data/VK08_TCCounts_1878-2020.dat', sep=\"\\s+\", header=None)\n",
        "df_VK08_TCCount = df_VK08_TCCount.rename(columns={0: \"Year\", 1:\"VK08_TCCount\"}).copy()\n",
        "df_VK08_TCCount"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9vjzQzgUjgk1",
        "outputId": "44152f74-398e-4aed-d0a0-179423155ff7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fa661221-37d8-4aee-85e3-5271f874f5c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>VK08_TCCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1878</td>\n",
              "      <td>15.370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1879</td>\n",
              "      <td>11.308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1880</td>\n",
              "      <td>14.084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1881</td>\n",
              "      <td>10.234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1882</td>\n",
              "      <td>9.183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>2016</td>\n",
              "      <td>15.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>2017</td>\n",
              "      <td>17.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>2018</td>\n",
              "      <td>15.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>2019</td>\n",
              "      <td>18.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>2020</td>\n",
              "      <td>30.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa661221-37d8-4aee-85e3-5271f874f5c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa661221-37d8-4aee-85e3-5271f874f5c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa661221-37d8-4aee-85e3-5271f874f5c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Year  VK08_TCCount\n",
              "0    1878        15.370\n",
              "1    1879        11.308\n",
              "2    1880        14.084\n",
              "3    1881        10.234\n",
              "4    1882         9.183\n",
              "..    ...           ...\n",
              "138  2016        15.000\n",
              "139  2017        17.000\n",
              "140  2018        15.000\n",
              "141  2019        18.000\n",
              "142  2020        30.000\n",
              "\n",
              "[143 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hurricanefinal = pd.DataFrame()"
      ],
      "metadata": {
        "id": "EIl-EphUxMYw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hurricanefinal['Year'] = df_HURDAT_TCCounts[0]\n",
        "df_hurricanefinal['HURRICANE_COUNT'] = df_HURDAT_TCCounts[1]\n",
        "\n",
        "df_hurricanefinal['ERSSTv5_ASO_MDRRelative'] = df_ERSSTv5_ASO_MDRRelative[0]\n",
        "df_hurricanefinal['ERSSTv5_ASO_MDR'] = df_ERSSTv5_ASO_MDR[0] \n",
        "df_hurricanefinal['ERSSTv5_ASO_MDR_anomalies'] = df_ERSSTv5_ASO_MDR_anomalies[0] \n",
        "df_hurricanefinal['ERSSTv5_ASO_MDR_tropics'] = df_ERSSTv5_ASO_MDR_tropics[0] \n",
        "df_hurricanefinal['ERSSTv5_ASO_MDR_tropics_anomalies'] = df_ERSSTv5_ASO_MDR_tropics_anomalies[0] \n",
        "df_hurricanefinal['ERSSTv5_ASO_MDR'] = df_ERSSTv5_ASO_MDR[0] \n",
        "\n",
        "df_hurricanefinal['NAO_DJFM_mean'] = df_NAO_DJFM_mean[1]\n",
        "df_hurricanefinal['NAO_MJ_mean'] = df_NAO_MJ_mean[1] \n",
        "\n",
        "df_hurricanefinal['Nino12_DJF'] = df_Nino12_DJF[1]\n",
        "df_hurricanefinal['Nino34_DJF'] = df_Nino34_DJF[1] \n",
        "df_hurricanefinal['Nino3_DJF'] = df_Nino3_DJF[1]"
      ],
      "metadata": {
        "id": "Is6yIuB3xXVu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hurricanefinal = pd.merge(df_hurricanefinal, df_AMM_JJASOM_mean,how = \"left\", on=['Year'])\n",
        "df_hurricanefinal = pd.merge(df_hurricanefinal, df_VK08_TCCount,how = \"left\", on=['Year'])\n",
        "df_hurricanefinal = pd.merge(df_hurricanefinal, df_SahelPrecipIndex_JJAS_mean,how = \"left\", on=['Year'])"
      ],
      "metadata": {
        "id": "Sk1HhCvrul1F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hurricanefinal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "x0PLB4K-xjyx",
        "outputId": "a750c7ab-f07b-473c-9f61-f133a9b05e87"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-11de04f4-0b0e-4fe8-8209-1d22c89a75b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>HURRICANE_COUNT</th>\n",
              "      <th>ERSSTv5_ASO_MDRRelative</th>\n",
              "      <th>ERSSTv5_ASO_MDR</th>\n",
              "      <th>ERSSTv5_ASO_MDR_anomalies</th>\n",
              "      <th>ERSSTv5_ASO_MDR_tropics</th>\n",
              "      <th>ERSSTv5_ASO_MDR_tropics_anomalies</th>\n",
              "      <th>NAO_DJFM_mean</th>\n",
              "      <th>NAO_MJ_mean</th>\n",
              "      <th>Nino12_DJF</th>\n",
              "      <th>Nino34_DJF</th>\n",
              "      <th>Nino3_DJF</th>\n",
              "      <th>AMM_JJASOM_mean</th>\n",
              "      <th>VK08_TCCount</th>\n",
              "      <th>SahelPrecipIndex_JJAS_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1870</td>\n",
              "      <td>11</td>\n",
              "      <td>0.239469</td>\n",
              "      <td>27.65656</td>\n",
              "      <td>-0.233739</td>\n",
              "      <td>25.89209</td>\n",
              "      <td>-0.473208</td>\n",
              "      <td>0.00275</td>\n",
              "      <td>1.0530</td>\n",
              "      <td>-0.850000</td>\n",
              "      <td>-0.540000</td>\n",
              "      <td>-0.573333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1871</td>\n",
              "      <td>8</td>\n",
              "      <td>-0.396031</td>\n",
              "      <td>27.01905</td>\n",
              "      <td>-0.871247</td>\n",
              "      <td>25.89008</td>\n",
              "      <td>-0.475217</td>\n",
              "      <td>0.05475</td>\n",
              "      <td>-1.9325</td>\n",
              "      <td>-1.156667</td>\n",
              "      <td>-0.640000</td>\n",
              "      <td>-0.710000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1872</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.743195</td>\n",
              "      <td>26.62783</td>\n",
              "      <td>-1.262471</td>\n",
              "      <td>25.84602</td>\n",
              "      <td>-0.519276</td>\n",
              "      <td>0.24850</td>\n",
              "      <td>-0.1640</td>\n",
              "      <td>-1.003333</td>\n",
              "      <td>-0.890000</td>\n",
              "      <td>-1.046667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1873</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.021984</td>\n",
              "      <td>27.38899</td>\n",
              "      <td>-0.501313</td>\n",
              "      <td>25.88597</td>\n",
              "      <td>-0.479329</td>\n",
              "      <td>1.77750</td>\n",
              "      <td>-0.0725</td>\n",
              "      <td>-1.156667</td>\n",
              "      <td>-0.896667</td>\n",
              "      <td>-1.276667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1874</td>\n",
              "      <td>7</td>\n",
              "      <td>0.161659</td>\n",
              "      <td>27.44587</td>\n",
              "      <td>-0.444434</td>\n",
              "      <td>25.75921</td>\n",
              "      <td>-0.606093</td>\n",
              "      <td>-0.53575</td>\n",
              "      <td>-1.3055</td>\n",
              "      <td>-0.676667</td>\n",
              "      <td>-0.740000</td>\n",
              "      <td>-0.793333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2016</td>\n",
              "      <td>15</td>\n",
              "      <td>0.082054</td>\n",
              "      <td>28.36498</td>\n",
              "      <td>0.474681</td>\n",
              "      <td>26.75793</td>\n",
              "      <td>0.392627</td>\n",
              "      <td>1.17500</td>\n",
              "      <td>-1.0485</td>\n",
              "      <td>0.423333</td>\n",
              "      <td>-0.286667</td>\n",
              "      <td>-0.056667</td>\n",
              "      <td>1.530000</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.5250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2017</td>\n",
              "      <td>17</td>\n",
              "      <td>0.221386</td>\n",
              "      <td>28.43985</td>\n",
              "      <td>0.549548</td>\n",
              "      <td>26.69346</td>\n",
              "      <td>0.328162</td>\n",
              "      <td>0.39925</td>\n",
              "      <td>-0.0835</td>\n",
              "      <td>-1.073333</td>\n",
              "      <td>-0.813333</td>\n",
              "      <td>-1.010000</td>\n",
              "      <td>2.618333</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.2625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2018</td>\n",
              "      <td>15</td>\n",
              "      <td>-0.232869</td>\n",
              "      <td>27.93210</td>\n",
              "      <td>0.041802</td>\n",
              "      <td>26.63997</td>\n",
              "      <td>0.274671</td>\n",
              "      <td>1.46525</td>\n",
              "      <td>0.3060</td>\n",
              "      <td>0.706667</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>-2.171667</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2019</td>\n",
              "      <td>18</td>\n",
              "      <td>-0.098519</td>\n",
              "      <td>28.12645</td>\n",
              "      <td>0.236148</td>\n",
              "      <td>26.69997</td>\n",
              "      <td>0.334666</td>\n",
              "      <td>2.22850</td>\n",
              "      <td>-0.3895</td>\n",
              "      <td>-0.113333</td>\n",
              "      <td>0.543333</td>\n",
              "      <td>0.273333</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>18.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>2020</td>\n",
              "      <td>30</td>\n",
              "      <td>0.183437</td>\n",
              "      <td>28.35310</td>\n",
              "      <td>0.462798</td>\n",
              "      <td>26.64466</td>\n",
              "      <td>0.279361</td>\n",
              "      <td>-0.13500</td>\n",
              "      <td>-0.8060</td>\n",
              "      <td>-0.633000</td>\n",
              "      <td>-0.987000</td>\n",
              "      <td>-0.650000</td>\n",
              "      <td>1.467830</td>\n",
              "      <td>30.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11de04f4-0b0e-4fe8-8209-1d22c89a75b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11de04f4-0b0e-4fe8-8209-1d22c89a75b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11de04f4-0b0e-4fe8-8209-1d22c89a75b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Year  HURRICANE_COUNT  ...  VK08_TCCount  SahelPrecipIndex_JJAS_mean\n",
              "0    1870               11  ...           NaN                         NaN\n",
              "1    1871                8  ...           NaN                         NaN\n",
              "2    1872                5  ...           NaN                         NaN\n",
              "3    1873                5  ...           NaN                         NaN\n",
              "4    1874                7  ...           NaN                         NaN\n",
              "..    ...              ...  ...           ...                         ...\n",
              "146  2016               15  ...          15.0                      2.5250\n",
              "147  2017               17  ...          17.0                      1.2625\n",
              "148  2018               15  ...          15.0                         NaN\n",
              "149  2019               18  ...          18.0                         NaN\n",
              "150  2020               30  ...          30.0                         NaN\n",
              "\n",
              "[151 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hurricanefinalVK08Counts = df_hurricanefinal.dropna(subset=['VK08_TCCount'])"
      ],
      "metadata": {
        "id": "Xka4mURrvCoj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize =(10, 7))\n",
        "# Creating plot\n",
        "plt.boxplot(df_hurricanefinalVK08Counts['VK08_TCCount'])\n",
        "# show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "-T6k2CLZcBqd",
        "outputId": "491bd1c8-59a6-42a2-c4ef-7a9cae1b0eed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hurricanefinalVK08Counts.head(70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "UVWOAC1ScO2N",
        "outputId": "c02645b8-7293-4fa9-a6fe-d4cac0e40396"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-13cfc85a-dc29-4595-9b6d-15b5104601c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>HURRICANE_COUNT</th>\n",
              "      <th>ERSSTv5_ASO_MDRRelative</th>\n",
              "      <th>ERSSTv5_ASO_MDR</th>\n",
              "      <th>ERSSTv5_ASO_MDR_anomalies</th>\n",
              "      <th>ERSSTv5_ASO_MDR_tropics</th>\n",
              "      <th>ERSSTv5_ASO_MDR_tropics_anomalies</th>\n",
              "      <th>NAO_DJFM_mean</th>\n",
              "      <th>NAO_MJ_mean</th>\n",
              "      <th>Nino12_DJF</th>\n",
              "      <th>Nino34_DJF</th>\n",
              "      <th>Nino3_DJF</th>\n",
              "      <th>AMM_JJASOM_mean</th>\n",
              "      <th>VK08_TCCount</th>\n",
              "      <th>SahelPrecipIndex_JJAS_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1878</td>\n",
              "      <td>12</td>\n",
              "      <td>0.782837</td>\n",
              "      <td>28.55411</td>\n",
              "      <td>0.663813</td>\n",
              "      <td>26.24628</td>\n",
              "      <td>-0.119023</td>\n",
              "      <td>-0.81125</td>\n",
              "      <td>-0.6320</td>\n",
              "      <td>-0.373333</td>\n",
              "      <td>-0.493333</td>\n",
              "      <td>-0.540000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.370</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1879</td>\n",
              "      <td>8</td>\n",
              "      <td>0.591066</td>\n",
              "      <td>28.04251</td>\n",
              "      <td>0.152207</td>\n",
              "      <td>25.92644</td>\n",
              "      <td>-0.438859</td>\n",
              "      <td>0.74400</td>\n",
              "      <td>0.0680</td>\n",
              "      <td>-0.133333</td>\n",
              "      <td>-0.916667</td>\n",
              "      <td>-0.873333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.308</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1880</td>\n",
              "      <td>11</td>\n",
              "      <td>0.067194</td>\n",
              "      <td>27.45252</td>\n",
              "      <td>-0.437781</td>\n",
              "      <td>25.86032</td>\n",
              "      <td>-0.504975</td>\n",
              "      <td>-1.30050</td>\n",
              "      <td>-0.6660</td>\n",
              "      <td>-0.103333</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.084</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1881</td>\n",
              "      <td>7</td>\n",
              "      <td>0.286079</td>\n",
              "      <td>27.76526</td>\n",
              "      <td>-0.125039</td>\n",
              "      <td>25.95418</td>\n",
              "      <td>-0.411118</td>\n",
              "      <td>3.16025</td>\n",
              "      <td>0.4140</td>\n",
              "      <td>-0.673333</td>\n",
              "      <td>-0.456667</td>\n",
              "      <td>-0.613333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.234</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1882</td>\n",
              "      <td>6</td>\n",
              "      <td>0.081678</td>\n",
              "      <td>27.46557</td>\n",
              "      <td>-0.424733</td>\n",
              "      <td>25.85889</td>\n",
              "      <td>-0.506411</td>\n",
              "      <td>0.29575</td>\n",
              "      <td>-0.6590</td>\n",
              "      <td>-1.133333</td>\n",
              "      <td>-0.566667</td>\n",
              "      <td>-0.766667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.183</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1943</td>\n",
              "      <td>10</td>\n",
              "      <td>0.058492</td>\n",
              "      <td>27.60058</td>\n",
              "      <td>-0.289724</td>\n",
              "      <td>26.01708</td>\n",
              "      <td>-0.348216</td>\n",
              "      <td>0.20825</td>\n",
              "      <td>2.0405</td>\n",
              "      <td>-0.366667</td>\n",
              "      <td>-0.226667</td>\n",
              "      <td>-0.296667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.960</td>\n",
              "      <td>3.0675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>1944</td>\n",
              "      <td>11</td>\n",
              "      <td>0.005687</td>\n",
              "      <td>27.81003</td>\n",
              "      <td>-0.080266</td>\n",
              "      <td>26.27935</td>\n",
              "      <td>-0.085954</td>\n",
              "      <td>1.33025</td>\n",
              "      <td>-1.1770</td>\n",
              "      <td>-0.480000</td>\n",
              "      <td>-0.363333</td>\n",
              "      <td>-0.460000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.556</td>\n",
              "      <td>0.1775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>1945</td>\n",
              "      <td>11</td>\n",
              "      <td>0.721561</td>\n",
              "      <td>28.54538</td>\n",
              "      <td>0.655082</td>\n",
              "      <td>26.29882</td>\n",
              "      <td>-0.066479</td>\n",
              "      <td>0.44100</td>\n",
              "      <td>-0.2360</td>\n",
              "      <td>-0.476667</td>\n",
              "      <td>-0.406667</td>\n",
              "      <td>-0.630000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.077</td>\n",
              "      <td>2.8950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>1946</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.030884</td>\n",
              "      <td>27.34187</td>\n",
              "      <td>-0.548431</td>\n",
              "      <td>25.84775</td>\n",
              "      <td>-0.517547</td>\n",
              "      <td>-1.06850</td>\n",
              "      <td>-0.0735</td>\n",
              "      <td>-0.330000</td>\n",
              "      <td>0.096667</td>\n",
              "      <td>-0.040000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.710</td>\n",
              "      <td>2.1600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>1947</td>\n",
              "      <td>9</td>\n",
              "      <td>-0.233403</td>\n",
              "      <td>27.05178</td>\n",
              "      <td>-0.838521</td>\n",
              "      <td>25.76018</td>\n",
              "      <td>-0.605119</td>\n",
              "      <td>1.23900</td>\n",
              "      <td>-0.5015</td>\n",
              "      <td>-0.010000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.110000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.188</td>\n",
              "      <td>1.2575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13cfc85a-dc29-4595-9b6d-15b5104601c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13cfc85a-dc29-4595-9b6d-15b5104601c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13cfc85a-dc29-4595-9b6d-15b5104601c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Year  HURRICANE_COUNT  ...  VK08_TCCount  SahelPrecipIndex_JJAS_mean\n",
              "8   1878               12  ...        15.370                         NaN\n",
              "9   1879                8  ...        11.308                         NaN\n",
              "10  1880               11  ...        14.084                         NaN\n",
              "11  1881                7  ...        10.234                         NaN\n",
              "12  1882                6  ...         9.183                         NaN\n",
              "..   ...              ...  ...           ...                         ...\n",
              "73  1943               10  ...        11.960                      3.0675\n",
              "74  1944               11  ...        12.556                      0.1775\n",
              "75  1945               11  ...        13.077                      2.8950\n",
              "76  1946                6  ...         7.710                      2.1600\n",
              "77  1947                9  ...        10.188                      1.2575\n",
              "\n",
              "[70 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XG BOOST"
      ],
      "metadata": {
        "id": "HzMDlInLyCUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import mean_squared_error as MSE \n",
        "import matplotlib.pyplot as plt\n",
        "!pip install eli5\n",
        "from eli5 import show_weights\n",
        "from eli5 import explain_prediction\n",
        "from IPython.display import display\n",
        "import eli5\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJbyhuGNxkvm",
        "outputId": "c342c233-dff5-4e59-f820-5b1b868f5f15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eli5\n",
            "  Downloading eli5-0.11.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 106 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.0.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.21.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (21.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (2.0.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error,mean_absolute_error"
      ],
      "metadata": {
        "id": "Oq1NR7bWyKgD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test2005 = df_hurricanefinalVK08Counts.loc[df_hurricanefinalVK08Counts.Year == 2005].drop(columns=['HURRICANE_COUNT',\"VK08_TCCount\", 'Year'],axis=1)\n",
        "test2020 = df_hurricanefinalVK08Counts.loc[df_hurricanefinalVK08Counts.Year == 2020].drop(columns=['HURRICANE_COUNT',\"VK08_TCCount\", 'Year'],axis=1)\n",
        "test1999 = df_hurricanefinalVK08Counts.loc[df_hurricanefinalVK08Counts.Year == 1999].drop(columns=['HURRICANE_COUNT',\"VK08_TCCount\", 'Year'],axis=1)"
      ],
      "metadata": {
        "id": "oAbyfY10bqqQ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hurricanefinal1 = df_hurricanefinalVK08Counts.loc[df_hurricanefinal.Year != 2005]\n",
        "#df_hurricanefinal1 = df_hurricanefinal1.loc[df_hurricanefinal.Year != 2020]\n",
        "\n",
        "X = df_hurricanefinal1.drop(columns=['HURRICANE_COUNT',\"VK08_TCCount\", 'Year'],axis=1)\n",
        "y = df_hurricanefinal1['VK08_TCCount']\n",
        "#outliers across all years\n",
        "#3- fold cross validation - see which years we under predicted\n",
        "# Splitting \n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                      test_size = 0.3) \n",
        "  \n",
        "# Instantiation \n",
        "xgb_r = xgb.XGBRegressor(objective ='reg:linear', \n",
        "                  n_estimators = 10) \n",
        "  \n",
        "# Fitting the model \n",
        "xgb_r.fit(train_X, train_y) \n",
        "  \n",
        "# Predict the model \n",
        "pred = xgb_r.predict(test_X) \n",
        "  \n",
        "# RMSE Computation \n",
        "rmse = mean_absolute_error(test_y,pred)\n",
        "\n",
        "print(\"MAE : % f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2CYHaTYyORf",
        "outputId": "4aef00f7-4174-4699-fb97-872abe768a0c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:23:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "MAE :  3.497982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain = xgb.DMatrix(train_X, label=train_y)\n",
        "dtest = xgb.DMatrix(test_X, label=test_y)"
      ],
      "metadata": {
        "id": "RvljnLvcya76"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_boost_round = 999"
      ],
      "metadata": {
        "id": "SPrEfcgLkMRF"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = { 'max_depth': [3,6,10],\n",
        "           'learning_rate': [0.01, 0.05, 0.1],\n",
        "           'min_child_weight': [.05,1,1.5,2],\n",
        "           'n_estimators': [100, 500, 1000],\n",
        "           'gamma': [0,.5,1,2],\n",
        "           'colsample_bytree': [0.3, 0.7]}\n",
        "\n",
        "xgbr = xgb.XGBRegressor(seed = 20)\n",
        "clf = GridSearchCV(estimator=xgbr, \n",
        "                   param_grid=params,\n",
        "                   scoring='neg_mean_squared_error', \n",
        "                   verbose=1)\n",
        "clf.fit(X, y)\n",
        "print(\"Best parameters:\", clf.best_params_)\n",
        "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RZTx6YCUnD2L",
        "outputId": "0777bd84-8298-4880-bf4f-a00ceeedc359"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:23:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-b2784576fcc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                    verbose=1)\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lowest RMSE: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'colsample_bytree': 0.3, 'gamma': 2, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 0.05, 'n_estimators': 100}\n",
        "params['eval_metric'] = \"mae\""
      ],
      "metadata": {
        "id": "y4GVSoTWyehV"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgmodel = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=num_boost_round,\n",
        "    evals=[(dtest, \"Test\")],\n",
        "    early_stopping_rounds=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b39_loo_ykjd",
        "outputId": "40e4177a-c9a3-48f5-9af8-f42a6fc199c3"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tTest-mae:8.80598\n",
            "Will train until Test-mae hasn't improved in 10 rounds.\n",
            "[1]\tTest-mae:8.33986\n",
            "[2]\tTest-mae:7.90317\n",
            "[3]\tTest-mae:7.49045\n",
            "[4]\tTest-mae:7.0941\n",
            "[5]\tTest-mae:6.66907\n",
            "[6]\tTest-mae:6.32433\n",
            "[7]\tTest-mae:5.96456\n",
            "[8]\tTest-mae:5.64836\n",
            "[9]\tTest-mae:5.35319\n",
            "[10]\tTest-mae:5.10377\n",
            "[11]\tTest-mae:4.87965\n",
            "[12]\tTest-mae:4.66213\n",
            "[13]\tTest-mae:4.44628\n",
            "[14]\tTest-mae:4.25524\n",
            "[15]\tTest-mae:4.08175\n",
            "[16]\tTest-mae:3.93182\n",
            "[17]\tTest-mae:3.77352\n",
            "[18]\tTest-mae:3.62878\n",
            "[19]\tTest-mae:3.50624\n",
            "[20]\tTest-mae:3.40125\n",
            "[21]\tTest-mae:3.32379\n",
            "[22]\tTest-mae:3.21703\n",
            "[23]\tTest-mae:3.14006\n",
            "[24]\tTest-mae:3.06793\n",
            "[25]\tTest-mae:3.01233\n",
            "[26]\tTest-mae:2.95264\n",
            "[27]\tTest-mae:2.90183\n",
            "[28]\tTest-mae:2.85843\n",
            "[29]\tTest-mae:2.80905\n",
            "[30]\tTest-mae:2.76396\n",
            "[31]\tTest-mae:2.72212\n",
            "[32]\tTest-mae:2.69438\n",
            "[33]\tTest-mae:2.671\n",
            "[34]\tTest-mae:2.63999\n",
            "[35]\tTest-mae:2.60726\n",
            "[36]\tTest-mae:2.59271\n",
            "[37]\tTest-mae:2.57089\n",
            "[38]\tTest-mae:2.56649\n",
            "[39]\tTest-mae:2.55057\n",
            "[40]\tTest-mae:2.54425\n",
            "[41]\tTest-mae:2.53675\n",
            "[42]\tTest-mae:2.52299\n",
            "[43]\tTest-mae:2.5154\n",
            "[44]\tTest-mae:2.50435\n",
            "[45]\tTest-mae:2.49771\n",
            "[46]\tTest-mae:2.48715\n",
            "[47]\tTest-mae:2.48114\n",
            "[48]\tTest-mae:2.4707\n",
            "[49]\tTest-mae:2.47389\n",
            "[50]\tTest-mae:2.47143\n",
            "[51]\tTest-mae:2.47028\n",
            "[52]\tTest-mae:2.47573\n",
            "[53]\tTest-mae:2.47116\n",
            "[54]\tTest-mae:2.46235\n",
            "[55]\tTest-mae:2.46061\n",
            "[56]\tTest-mae:2.45176\n",
            "[57]\tTest-mae:2.44451\n",
            "[58]\tTest-mae:2.44055\n",
            "[59]\tTest-mae:2.43548\n",
            "[60]\tTest-mae:2.44437\n",
            "[61]\tTest-mae:2.43871\n",
            "[62]\tTest-mae:2.44575\n",
            "[63]\tTest-mae:2.45216\n",
            "[64]\tTest-mae:2.45241\n",
            "[65]\tTest-mae:2.46188\n",
            "[66]\tTest-mae:2.45953\n",
            "[67]\tTest-mae:2.45579\n",
            "[68]\tTest-mae:2.44656\n",
            "[69]\tTest-mae:2.45189\n",
            "Stopping. Best iteration:\n",
            "[59]\tTest-mae:2.43548\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_weights(xgmodel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "Rsyi2RqSynFn",
        "outputId": "6b75bc73-906f-42bf-be5d-73c0a2fe96c2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1452\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ERSSTv5_ASO_MDRRelative\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 82.50%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1200\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                AMM_JJASOM_mean\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 84.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ERSSTv5_ASO_MDR_anomalies\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 84.65%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0995\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Nino34_DJF\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 85.33%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0933\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ERSSTv5_ASO_MDR\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 86.20%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0854\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Nino3_DJF\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 86.83%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0800\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                SahelPrecipIndex_JJAS_mean\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.98%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0619\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Nino12_DJF\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 89.06%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0613\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                NAO_MJ_mean\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 89.39%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0587\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ERSSTv5_ASO_MDR_tropics_anomalies\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.76%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0481\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ERSSTv5_ASO_MDR_tropics\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.10%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0457\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                NAO_DJFM_mean\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = [25, 12.5]"
      ],
      "metadata": {
        "id": "hmWAzi92bRDh"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.plot_importance(xgmodel, max_num_features=25)\n",
        "plt.rcParams['figure.figsize'] = [5, 5]\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "TVl6dqkXyqeG",
        "outputId": "5d54ffd2-753d-48b9-c2e5-7993474a913b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x900 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.plot_tree(xgmodel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "u5JGLV25y5gU",
        "outputId": "0c2f2760-3b53-4412-994b-22225c39252a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3943322c90>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explain_prediction(xgmodel, test2005.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "O9LDt6RQcPkq",
        "outputId": "ae636093-4870-4a19-8d4e-35d98290ab09"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (score <b>17.010</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +9.951\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.44%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.597\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.72%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.101\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Nino34_DJF\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.92%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.026\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        AMM_JJASOM_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 96.19%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.931\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDRRelative\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 96.81%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.724\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR_anomalies\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 96.84%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.712\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR_tropics\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.69%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.456\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Nino12_DJF\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 98.63%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.216\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR_tropics_anomalies\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 98.71%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.198\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        NAO_MJ_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 99.27%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.087\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        NAO_DJFM_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 99.59%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.038\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        SahelPrecipIndex_JJAS_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 99.68%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.027\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Nino3_DJF\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "Explanation(estimator='<xgboost.core.Booster object at 0x7f394357d090>', description='\\nFeatures with largest coefficients.\\n\\nFeature weights are calculated by following decision paths in trees\\nof an ensemble. Each leaf has an output score, and expected scores can also be\\nassigned to parent nodes. Contribution of one feature on the decision path\\nis how much expected score changes from parent to child. Weights of all \\nfeatures sum to the output score of the estimator.\\n\\nCaveats:\\n1. Feature weights just show if the feature contributed positively or\\n   negatively to the final score, and does not show how increasing or\\n   decreasing the feature value will change the prediction.\\n2. In some cases, feature weight can be close to zero for an important feature.\\n   For example, in a single tree that computes XOR function, the feature at the\\n   top of the tree will have zero weight because expected scores for both\\n   branches are equal, so decision at the top feature does not change the\\n   expected score. For an ensemble predicting XOR functions it might not be\\n   a problem, but it is not reliable if most trees happen to choose the same\\n   feature at the top.\\n', error=None, method='decision paths', is_regression=True, targets=[TargetExplanation(target='y', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='<BIAS>', weight=9.951418780472364, std=None, value=1.0), FeatureWeight(feature='ERSSTv5_ASO_MDR', weight=1.5972350905400525, std=None, value=28.43595), FeatureWeight(feature='Nino34_DJF', weight=1.101113261793985, std=None, value=-0.813333333), FeatureWeight(feature='AMM_JJASOM_mean', weight=1.0261245650002604, std=None, value=4.048333333), FeatureWeight(feature='ERSSTv5_ASO_MDRRelative', weight=0.9308052799941086, std=None, value=0.4560429), FeatureWeight(feature='ERSSTv5_ASO_MDR_anomalies', weight=0.7236107355880542, std=None, value=0.5456474), FeatureWeight(feature='ERSSTv5_ASO_MDR_tropics', weight=0.711747079418461, std=None, value=26.4549), FeatureWeight(feature='Nino12_DJF', weight=0.45615144646855543, std=None, value=-0.516666667), FeatureWeight(feature='ERSSTv5_ASO_MDR_tropics_anomalies', weight=0.21625896191183097, std=None, value=0.08960456), FeatureWeight(feature='NAO_MJ_mean', weight=0.19766112956309495, std=None, value=-0.5675), FeatureWeight(feature='NAO_DJFM_mean', weight=0.08732954061744, std=None, value=-0.81775), FeatureWeight(feature='SahelPrecipIndex_JJAS_mean', weight=0.03816547852455004, std=None, value=0.4725)], neg=[FeatureWeight(feature='Nino3_DJF', weight=-0.027415974192755873, std=None, value=-0.856666667)], pos_remaining=0, neg_remaining=0), proba=None, score=17.010205375699993, weighted_spans=None, heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explain_prediction(xgmodel, test2020.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "1u8lvfuKcfV5",
        "outputId": "e9cf8157-b01f-488d-e646-a93edea7b279"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (score <b>23.029</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +9.951\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 92.14%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.621\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Nino34_DJF\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 92.28%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.554\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.59%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.538\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        AMM_JJASOM_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.87%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.424\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDRRelative\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.98%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.006\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR_anomalies\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 96.06%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.978\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR_tropics\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 96.42%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.851\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Nino12_DJF\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.11%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.627\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Nino3_DJF\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.59%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.485\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR_tropics_anomalies\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.72%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.447\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        NAO_MJ_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.82%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.420\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        SahelPrecipIndex_JJAS_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 99.06%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.126\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        NAO_DJFM_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "Explanation(estimator='<xgboost.core.Booster object at 0x7f394357d090>', description='\\nFeatures with largest coefficients.\\n\\nFeature weights are calculated by following decision paths in trees\\nof an ensemble. Each leaf has an output score, and expected scores can also be\\nassigned to parent nodes. Contribution of one feature on the decision path\\nis how much expected score changes from parent to child. Weights of all \\nfeatures sum to the output score of the estimator.\\n\\nCaveats:\\n1. Feature weights just show if the feature contributed positively or\\n   negatively to the final score, and does not show how increasing or\\n   decreasing the feature value will change the prediction.\\n2. In some cases, feature weight can be close to zero for an important feature.\\n   For example, in a single tree that computes XOR function, the feature at the\\n   top of the tree will have zero weight because expected scores for both\\n   branches are equal, so decision at the top feature does not change the\\n   expected score. For an ensemble predicting XOR functions it might not be\\n   a problem, but it is not reliable if most trees happen to choose the same\\n   feature at the top.\\n', error=None, method='decision paths', is_regression=True, targets=[TargetExplanation(target='y', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='<BIAS>', weight=9.951418780472364, std=None, value=1.0), FeatureWeight(feature='Nino34_DJF', weight=2.6206003262319113, std=None, value=-0.987), FeatureWeight(feature='ERSSTv5_ASO_MDR', weight=2.554079185224881, std=None, value=28.3531), FeatureWeight(feature='AMM_JJASOM_mean', weight=1.537871325355816, std=None, value=1.46783), FeatureWeight(feature='ERSSTv5_ASO_MDRRelative', weight=1.423944148025139, std=None, value=0.183437), FeatureWeight(feature='ERSSTv5_ASO_MDR_anomalies', weight=1.0060756561630129, std=None, value=0.4627979), FeatureWeight(feature='ERSSTv5_ASO_MDR_tropics', weight=0.978148254978299, std=None, value=26.64466), FeatureWeight(feature='Nino12_DJF', weight=0.851260903485609, std=None, value=-0.633), FeatureWeight(feature='Nino3_DJF', weight=0.6265594286213638, std=None, value=-0.65), FeatureWeight(feature='ERSSTv5_ASO_MDR_tropics_anomalies', weight=0.4854122361509699, std=None, value=0.2793609), FeatureWeight(feature='NAO_MJ_mean', weight=0.447481497818095, std=None, value=-0.806), FeatureWeight(feature='SahelPrecipIndex_JJAS_mean', weight=0.4202360363550995, std=None, value=nan), FeatureWeight(feature='NAO_DJFM_mean', weight=0.12585409911744, std=None, value=-0.135)], neg=[], pos_remaining=0, neg_remaining=0), proba=None, score=23.02894187800001, weighted_spans=None, heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explain_prediction(xgmodel, test1999.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "Z-fkF7aYcjuO",
        "outputId": "e73805c0-7ac6-4023-99b8-f2ffd0fed022"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (score <b>11.102</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +9.951\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.56%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.161\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Nino34_DJF\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.07%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.641\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDRRelative\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 98.61%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.221\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR_anomalies\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 98.76%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.187\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.179\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        SahelPrecipIndex_JJAS_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 99.33%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.078\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Nino3_DJF\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 99.34%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.076\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Nino12_DJF\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 99.62%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.034\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR_tropics_anomalies\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 98.84%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.171\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        NAO_DJFM_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 98.61%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.221\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        AMM_JJASOM_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 98.49%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.248\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ERSSTv5_ASO_MDR_tropics\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 96.62%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.786\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        NAO_MJ_mean\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "Explanation(estimator='<xgboost.core.Booster object at 0x7f394357d090>', description='\\nFeatures with largest coefficients.\\n\\nFeature weights are calculated by following decision paths in trees\\nof an ensemble. Each leaf has an output score, and expected scores can also be\\nassigned to parent nodes. Contribution of one feature on the decision path\\nis how much expected score changes from parent to child. Weights of all \\nfeatures sum to the output score of the estimator.\\n\\nCaveats:\\n1. Feature weights just show if the feature contributed positively or\\n   negatively to the final score, and does not show how increasing or\\n   decreasing the feature value will change the prediction.\\n2. In some cases, feature weight can be close to zero for an important feature.\\n   For example, in a single tree that computes XOR function, the feature at the\\n   top of the tree will have zero weight because expected scores for both\\n   branches are equal, so decision at the top feature does not change the\\n   expected score. For an ensemble predicting XOR functions it might not be\\n   a problem, but it is not reliable if most trees happen to choose the same\\n   feature at the top.\\n', error=None, method='decision paths', is_regression=True, targets=[TargetExplanation(target='y', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='<BIAS>', weight=9.951418780472364, std=None, value=1.0), FeatureWeight(feature='Nino34_DJF', weight=1.1606327053528838, std=None, value=-1.62), FeatureWeight(feature='ERSSTv5_ASO_MDRRelative', weight=0.6405155462530172, std=None, value=0.2835747), FeatureWeight(feature='ERSSTv5_ASO_MDR_anomalies', weight=0.22128555542108236, std=None, value=0.04391745), FeatureWeight(feature='ERSSTv5_ASO_MDR', weight=0.18731314727311246, std=None, value=27.93422), FeatureWeight(feature='SahelPrecipIndex_JJAS_mean', weight=0.17895323041855324, std=None, value=2.64), FeatureWeight(feature='Nino3_DJF', weight=0.07802866029747299, std=None, value=-1.44), FeatureWeight(feature='Nino12_DJF', weight=0.07580416034597914, std=None, value=-0.806666667), FeatureWeight(feature='ERSSTv5_ASO_MDR_tropics_anomalies', weight=0.03419811715986893, std=None, value=-0.2396572)], neg=[FeatureWeight(feature='NAO_MJ_mean', weight=-0.7864296428269819, std=None, value=1.2065), FeatureWeight(feature='ERSSTv5_ASO_MDR_tropics', weight=-0.24795140501723156, std=None, value=26.12564), FeatureWeight(feature='AMM_JJASOM_mean', weight=-0.2205204212657613, std=None, value=0.975), FeatureWeight(feature='NAO_DJFM_mean', weight=-0.1707947931133588, std=None, value=1.84575)], pos_remaining=0, neg_remaining=0), proba=None, score=11.102453640771007, weighted_spans=None, heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Neuron Neural Network"
      ],
      "metadata": {
        "id": "cTxHOINMnrZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hurricanefinal = df_hurricanefinal.fillna(0).copy()"
      ],
      "metadata": {
        "id": "AvyYQc_aoH-p"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gathering Test Years"
      ],
      "metadata": {
        "id": "MyKl90TRimgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test2005 = df_hurricanefinal.loc[df_hurricanefinal.Year == 2005].copy()\n",
        "test2005 = test2005.drop(columns=['HURRICANE_COUNT',\"VK08_TCCount\", 'Year'],axis=1)\n",
        "test2005 = pd.DataFrame(test2005)"
      ],
      "metadata": {
        "id": "wM0ZtiBlspZs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test2020 = df_hurricanefinal.loc[df_hurricanefinal.Year == 2020].copy()\n",
        "test2020 = test2020.drop(columns=['HURRICANE_COUNT',\"VK08_TCCount\", 'Year'],axis=1)\n",
        "test2020 = pd.DataFrame(test2020)\n"
      ],
      "metadata": {
        "id": "L-pCprgut3ax"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1999 = df_hurricanefinal.loc[df_hurricanefinal.Year == 1999].copy()\n",
        "test1999 = test1999.drop(columns=['HURRICANE_COUNT',\"VK08_TCCount\", 'Year'],axis=1)\n",
        "test1999 = pd.DataFrame(test1999)"
      ],
      "metadata": {
        "id": "lcUdMxU4t9No"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Scaling"
      ],
      "metadata": {
        "id": "TAIDQ3KsistG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4RnB9901f7W"
      },
      "source": [
        "#df_hurricanefinal1 = df_hurricanefinal.loc[df_hurricanefinal.Year != 2005]\n",
        "df_hurricanefinal1 = df_hurricanefinal.loc[df_hurricanefinal.Year != 2020]\n",
        "X = df_hurricanefinal1.drop(columns=['HURRICANE_COUNT',\"VK08_TCCount\", 'Year'],axis=1)\n",
        "y = df_hurricanefinal1['HURRICANE_COUNT']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1SUZET21ptl"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train= scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "test2005 = scaler.transform(test2005)\n",
        "test2020 = scaler.transform(test2020)\n",
        "test1999 = scaler.transform(test1999)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Creation and Training"
      ],
      "metadata": {
        "id": "YB22_mBFi4EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "id": "e_v8Vg9Niid8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57vdqpM31rvY"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(2,activation='relu'))\n",
        "model.add(Dense(2,activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mae')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE3a5Gw51uHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3bc86a-0b17-47b2-995b-aa3cba4abf2d"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "model.fit(x=X_train,y=y_train.values,\n",
        "          validation_data=(X_test,y_test.values),\n",
        "          batch_size=128,epochs=10000, callbacks=[early_stop])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 8.5812 - val_loss: 8.5659\n",
            "Epoch 2/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.5625 - val_loss: 8.5468\n",
            "Epoch 3/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.5437 - val_loss: 8.5277\n",
            "Epoch 4/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8.5249 - val_loss: 8.5086\n",
            "Epoch 5/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.5061 - val_loss: 8.4894\n",
            "Epoch 6/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.4873 - val_loss: 8.4702\n",
            "Epoch 7/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.4686 - val_loss: 8.4510\n",
            "Epoch 8/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.4498 - val_loss: 8.4317\n",
            "Epoch 9/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.4310 - val_loss: 8.4124\n",
            "Epoch 10/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8.4122 - val_loss: 8.3932\n",
            "Epoch 11/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8.3934 - val_loss: 8.3741\n",
            "Epoch 12/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.3746 - val_loss: 8.3549\n",
            "Epoch 13/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8.3557 - val_loss: 8.3357\n",
            "Epoch 14/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.3369 - val_loss: 8.3166\n",
            "Epoch 15/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.3180 - val_loss: 8.2972\n",
            "Epoch 16/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8.2992 - val_loss: 8.2776\n",
            "Epoch 17/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8.2803 - val_loss: 8.2581\n",
            "Epoch 18/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8.2613 - val_loss: 8.2384\n",
            "Epoch 19/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.2424 - val_loss: 8.2188\n",
            "Epoch 20/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.2235 - val_loss: 8.1991\n",
            "Epoch 21/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.2045 - val_loss: 8.1794\n",
            "Epoch 22/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.1856 - val_loss: 8.1596\n",
            "Epoch 23/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.1665 - val_loss: 8.1398\n",
            "Epoch 24/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.1475 - val_loss: 8.1200\n",
            "Epoch 25/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.1285 - val_loss: 8.1003\n",
            "Epoch 26/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.1094 - val_loss: 8.0805\n",
            "Epoch 27/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.0904 - val_loss: 8.0606\n",
            "Epoch 28/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.0712 - val_loss: 8.0406\n",
            "Epoch 29/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 8.0521 - val_loss: 8.0207\n",
            "Epoch 30/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.0330 - val_loss: 8.0007\n",
            "Epoch 31/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.0138 - val_loss: 7.9806\n",
            "Epoch 32/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.9946 - val_loss: 7.9605\n",
            "Epoch 33/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.9754 - val_loss: 7.9404\n",
            "Epoch 34/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.9561 - val_loss: 7.9202\n",
            "Epoch 35/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.9369 - val_loss: 7.9000\n",
            "Epoch 36/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.9182 - val_loss: 7.8797\n",
            "Epoch 37/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.8994 - val_loss: 7.8595\n",
            "Epoch 38/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.8808 - val_loss: 7.8393\n",
            "Epoch 39/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.8621 - val_loss: 7.8190\n",
            "Epoch 40/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.8434 - val_loss: 7.7987\n",
            "Epoch 41/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.8247 - val_loss: 7.7785\n",
            "Epoch 42/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.8060 - val_loss: 7.7581\n",
            "Epoch 43/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.7874 - val_loss: 7.7379\n",
            "Epoch 44/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.7687 - val_loss: 7.7177\n",
            "Epoch 45/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.7501 - val_loss: 7.6974\n",
            "Epoch 46/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.7315 - val_loss: 7.6771\n",
            "Epoch 47/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.7129 - val_loss: 7.6568\n",
            "Epoch 48/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.6943 - val_loss: 7.6365\n",
            "Epoch 49/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.6758 - val_loss: 7.6161\n",
            "Epoch 50/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.6572 - val_loss: 7.5958\n",
            "Epoch 51/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.6387 - val_loss: 7.5755\n",
            "Epoch 52/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.6202 - val_loss: 7.5552\n",
            "Epoch 53/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.6016 - val_loss: 7.5348\n",
            "Epoch 54/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.5830 - val_loss: 7.5144\n",
            "Epoch 55/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.5645 - val_loss: 7.4940\n",
            "Epoch 56/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.5459 - val_loss: 7.4737\n",
            "Epoch 57/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.5273 - val_loss: 7.4534\n",
            "Epoch 58/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.5087 - val_loss: 7.4331\n",
            "Epoch 59/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.4901 - val_loss: 7.4128\n",
            "Epoch 60/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.4715 - val_loss: 7.3925\n",
            "Epoch 61/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.4529 - val_loss: 7.3723\n",
            "Epoch 62/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.4343 - val_loss: 7.3521\n",
            "Epoch 63/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.4156 - val_loss: 7.3320\n",
            "Epoch 64/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.3970 - val_loss: 7.3119\n",
            "Epoch 65/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.3783 - val_loss: 7.2917\n",
            "Epoch 66/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.3596 - val_loss: 7.2716\n",
            "Epoch 67/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.3409 - val_loss: 7.2515\n",
            "Epoch 68/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.3222 - val_loss: 7.2314\n",
            "Epoch 69/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.3034 - val_loss: 7.2112\n",
            "Epoch 70/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.2846 - val_loss: 7.1910\n",
            "Epoch 71/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.2658 - val_loss: 7.1707\n",
            "Epoch 72/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.2470 - val_loss: 7.1503\n",
            "Epoch 73/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.2282 - val_loss: 7.1300\n",
            "Epoch 74/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.2094 - val_loss: 7.1095\n",
            "Epoch 75/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.1906 - val_loss: 7.0891\n",
            "Epoch 76/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.1718 - val_loss: 7.0694\n",
            "Epoch 77/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.1529 - val_loss: 7.0498\n",
            "Epoch 78/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.1341 - val_loss: 7.0302\n",
            "Epoch 79/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.1152 - val_loss: 7.0106\n",
            "Epoch 80/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.0963 - val_loss: 6.9910\n",
            "Epoch 81/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.0773 - val_loss: 6.9713\n",
            "Epoch 82/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.0583 - val_loss: 6.9516\n",
            "Epoch 83/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.0392 - val_loss: 6.9319\n",
            "Epoch 84/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.0201 - val_loss: 6.9122\n",
            "Epoch 85/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.0009 - val_loss: 6.8924\n",
            "Epoch 86/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.9817 - val_loss: 6.8726\n",
            "Epoch 87/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.9625 - val_loss: 6.8527\n",
            "Epoch 88/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.9432 - val_loss: 6.8328\n",
            "Epoch 89/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.9238 - val_loss: 6.8129\n",
            "Epoch 90/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.9045 - val_loss: 6.7929\n",
            "Epoch 91/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.8850 - val_loss: 6.7728\n",
            "Epoch 92/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.8656 - val_loss: 6.7527\n",
            "Epoch 93/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.8461 - val_loss: 6.7325\n",
            "Epoch 94/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.8265 - val_loss: 6.7123\n",
            "Epoch 95/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.8069 - val_loss: 6.6921\n",
            "Epoch 96/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.7873 - val_loss: 6.6719\n",
            "Epoch 97/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.7676 - val_loss: 6.6516\n",
            "Epoch 98/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.7478 - val_loss: 6.6312\n",
            "Epoch 99/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.7280 - val_loss: 6.6107\n",
            "Epoch 100/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 6.7081 - val_loss: 6.5902\n",
            "Epoch 101/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.6883 - val_loss: 6.5697\n",
            "Epoch 102/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.6684 - val_loss: 6.5490\n",
            "Epoch 103/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.6484 - val_loss: 6.5283\n",
            "Epoch 104/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.6284 - val_loss: 6.5076\n",
            "Epoch 105/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.6083 - val_loss: 6.4868\n",
            "Epoch 106/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.5882 - val_loss: 6.4659\n",
            "Epoch 107/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.5680 - val_loss: 6.4450\n",
            "Epoch 108/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.5477 - val_loss: 6.4239\n",
            "Epoch 109/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.5274 - val_loss: 6.4029\n",
            "Epoch 110/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.5070 - val_loss: 6.3817\n",
            "Epoch 111/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.4865 - val_loss: 6.3605\n",
            "Epoch 112/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.4660 - val_loss: 6.3393\n",
            "Epoch 113/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.4453 - val_loss: 6.3179\n",
            "Epoch 114/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.4247 - val_loss: 6.2965\n",
            "Epoch 115/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.4039 - val_loss: 6.2751\n",
            "Epoch 116/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.3832 - val_loss: 6.2536\n",
            "Epoch 117/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.3627 - val_loss: 6.2321\n",
            "Epoch 118/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.3421 - val_loss: 6.2105\n",
            "Epoch 119/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.3216 - val_loss: 6.1889\n",
            "Epoch 120/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.3010 - val_loss: 6.1673\n",
            "Epoch 121/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.2804 - val_loss: 6.1456\n",
            "Epoch 122/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.2598 - val_loss: 6.1239\n",
            "Epoch 123/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.2390 - val_loss: 6.1022\n",
            "Epoch 124/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.2183 - val_loss: 6.0804\n",
            "Epoch 125/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.1976 - val_loss: 6.0587\n",
            "Epoch 126/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.1772 - val_loss: 6.0370\n",
            "Epoch 127/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.1568 - val_loss: 6.0152\n",
            "Epoch 128/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.1363 - val_loss: 5.9934\n",
            "Epoch 129/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.1158 - val_loss: 5.9716\n",
            "Epoch 130/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.0953 - val_loss: 5.9497\n",
            "Epoch 131/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.0748 - val_loss: 5.9278\n",
            "Epoch 132/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.0542 - val_loss: 5.9058\n",
            "Epoch 133/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.0336 - val_loss: 5.8837\n",
            "Epoch 134/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.0129 - val_loss: 5.8616\n",
            "Epoch 135/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.9921 - val_loss: 5.8395\n",
            "Epoch 136/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.9713 - val_loss: 5.8172\n",
            "Epoch 137/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.9504 - val_loss: 5.7949\n",
            "Epoch 138/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.9294 - val_loss: 5.7726\n",
            "Epoch 139/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.9084 - val_loss: 5.7502\n",
            "Epoch 140/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.8873 - val_loss: 5.7278\n",
            "Epoch 141/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.8662 - val_loss: 5.7052\n",
            "Epoch 142/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.8449 - val_loss: 5.6826\n",
            "Epoch 143/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.8237 - val_loss: 5.6600\n",
            "Epoch 144/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.8023 - val_loss: 5.6372\n",
            "Epoch 145/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.7808 - val_loss: 5.6144\n",
            "Epoch 146/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.7593 - val_loss: 5.5914\n",
            "Epoch 147/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.7378 - val_loss: 5.5684\n",
            "Epoch 148/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.7161 - val_loss: 5.5454\n",
            "Epoch 149/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.6944 - val_loss: 5.5222\n",
            "Epoch 150/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.6726 - val_loss: 5.4991\n",
            "Epoch 151/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.6513 - val_loss: 5.4759\n",
            "Epoch 152/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.6298 - val_loss: 5.4526\n",
            "Epoch 153/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.6083 - val_loss: 5.4293\n",
            "Epoch 154/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.5868 - val_loss: 5.4059\n",
            "Epoch 155/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.5654 - val_loss: 5.3825\n",
            "Epoch 156/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.5443 - val_loss: 5.3591\n",
            "Epoch 157/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.5233 - val_loss: 5.3357\n",
            "Epoch 158/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.5025 - val_loss: 5.3123\n",
            "Epoch 159/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.4817 - val_loss: 5.2889\n",
            "Epoch 160/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.4609 - val_loss: 5.2655\n",
            "Epoch 161/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.4401 - val_loss: 5.2420\n",
            "Epoch 162/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.4192 - val_loss: 5.2185\n",
            "Epoch 163/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.3984 - val_loss: 5.1950\n",
            "Epoch 164/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.3775 - val_loss: 5.1714\n",
            "Epoch 165/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.3567 - val_loss: 5.1478\n",
            "Epoch 166/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.3362 - val_loss: 5.1242\n",
            "Epoch 167/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.3156 - val_loss: 5.1005\n",
            "Epoch 168/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.2951 - val_loss: 5.0769\n",
            "Epoch 169/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.2745 - val_loss: 5.0532\n",
            "Epoch 170/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.2539 - val_loss: 5.0295\n",
            "Epoch 171/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.2332 - val_loss: 5.0057\n",
            "Epoch 172/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.2125 - val_loss: 4.9818\n",
            "Epoch 173/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.1918 - val_loss: 4.9580\n",
            "Epoch 174/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.1711 - val_loss: 4.9341\n",
            "Epoch 175/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.1507 - val_loss: 4.9102\n",
            "Epoch 176/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.1307 - val_loss: 4.8863\n",
            "Epoch 177/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.1108 - val_loss: 4.8624\n",
            "Epoch 178/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 5.0909 - val_loss: 4.8385\n",
            "Epoch 179/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.0710 - val_loss: 4.8146\n",
            "Epoch 180/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.0512 - val_loss: 4.7908\n",
            "Epoch 181/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.0317 - val_loss: 4.7669\n",
            "Epoch 182/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.0122 - val_loss: 4.7434\n",
            "Epoch 183/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.9927 - val_loss: 4.7207\n",
            "Epoch 184/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.9733 - val_loss: 4.6979\n",
            "Epoch 185/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.9538 - val_loss: 4.6751\n",
            "Epoch 186/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.9342 - val_loss: 4.6523\n",
            "Epoch 187/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.9148 - val_loss: 4.6295\n",
            "Epoch 188/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.8958 - val_loss: 4.6067\n",
            "Epoch 189/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.8769 - val_loss: 4.5839\n",
            "Epoch 190/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.8579 - val_loss: 4.5611\n",
            "Epoch 191/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.8389 - val_loss: 4.5383\n",
            "Epoch 192/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.8200 - val_loss: 4.5155\n",
            "Epoch 193/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.8015 - val_loss: 4.4927\n",
            "Epoch 194/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.7830 - val_loss: 4.4699\n",
            "Epoch 195/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.7646 - val_loss: 4.4472\n",
            "Epoch 196/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.7461 - val_loss: 4.4244\n",
            "Epoch 197/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.7276 - val_loss: 4.4016\n",
            "Epoch 198/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.7091 - val_loss: 4.3788\n",
            "Epoch 199/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.6906 - val_loss: 4.3559\n",
            "Epoch 200/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.6721 - val_loss: 4.3331\n",
            "Epoch 201/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.6535 - val_loss: 4.3101\n",
            "Epoch 202/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.6349 - val_loss: 4.2871\n",
            "Epoch 203/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.6162 - val_loss: 4.2641\n",
            "Epoch 204/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.5975 - val_loss: 4.2410\n",
            "Epoch 205/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.5788 - val_loss: 4.2179\n",
            "Epoch 206/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.5600 - val_loss: 4.1946\n",
            "Epoch 207/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.5412 - val_loss: 4.1714\n",
            "Epoch 208/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.5223 - val_loss: 4.1480\n",
            "Epoch 209/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.5033 - val_loss: 4.1246\n",
            "Epoch 210/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.4843 - val_loss: 4.1011\n",
            "Epoch 211/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.4653 - val_loss: 4.0775\n",
            "Epoch 212/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.4462 - val_loss: 4.0539\n",
            "Epoch 213/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.4270 - val_loss: 4.0302\n",
            "Epoch 214/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.4078 - val_loss: 4.0064\n",
            "Epoch 215/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.3887 - val_loss: 3.9826\n",
            "Epoch 216/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.3697 - val_loss: 3.9588\n",
            "Epoch 217/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.3513 - val_loss: 3.9350\n",
            "Epoch 218/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.3329 - val_loss: 3.9113\n",
            "Epoch 219/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.3146 - val_loss: 3.8876\n",
            "Epoch 220/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.2968 - val_loss: 3.8639\n",
            "Epoch 221/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.2791 - val_loss: 3.8403\n",
            "Epoch 222/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.2617 - val_loss: 3.8167\n",
            "Epoch 223/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.2443 - val_loss: 3.7932\n",
            "Epoch 224/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.2270 - val_loss: 3.7697\n",
            "Epoch 225/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.2097 - val_loss: 3.7462\n",
            "Epoch 226/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.1925 - val_loss: 3.7228\n",
            "Epoch 227/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.1752 - val_loss: 3.7005\n",
            "Epoch 228/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.1580 - val_loss: 3.6783\n",
            "Epoch 229/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.1411 - val_loss: 3.6572\n",
            "Epoch 230/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.1242 - val_loss: 3.6372\n",
            "Epoch 231/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.1074 - val_loss: 3.6172\n",
            "Epoch 232/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.0911 - val_loss: 3.5978\n",
            "Epoch 233/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.0752 - val_loss: 3.5790\n",
            "Epoch 234/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.0595 - val_loss: 3.5603\n",
            "Epoch 235/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.0438 - val_loss: 3.5416\n",
            "Epoch 236/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.0282 - val_loss: 3.5230\n",
            "Epoch 237/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.0126 - val_loss: 3.5044\n",
            "Epoch 238/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9973 - val_loss: 3.4859\n",
            "Epoch 239/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.9824 - val_loss: 3.4675\n",
            "Epoch 240/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.9679 - val_loss: 3.4492\n",
            "Epoch 241/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9535 - val_loss: 3.4310\n",
            "Epoch 242/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.9391 - val_loss: 3.4129\n",
            "Epoch 243/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.9248 - val_loss: 3.3948\n",
            "Epoch 244/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.9106 - val_loss: 3.3767\n",
            "Epoch 245/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.8964 - val_loss: 3.3587\n",
            "Epoch 246/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.8821 - val_loss: 3.3406\n",
            "Epoch 247/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.8679 - val_loss: 3.3226\n",
            "Epoch 248/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.8538 - val_loss: 3.3046\n",
            "Epoch 249/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.8399 - val_loss: 3.2867\n",
            "Epoch 250/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.8264 - val_loss: 3.2688\n",
            "Epoch 251/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.8129 - val_loss: 3.2509\n",
            "Epoch 252/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.7998 - val_loss: 3.2332\n",
            "Epoch 253/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.7870 - val_loss: 3.2167\n",
            "Epoch 254/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.7749 - val_loss: 3.2013\n",
            "Epoch 255/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.7635 - val_loss: 3.1865\n",
            "Epoch 256/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.7538 - val_loss: 3.1726\n",
            "Epoch 257/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.7442 - val_loss: 3.1590\n",
            "Epoch 258/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.7349 - val_loss: 3.1456\n",
            "Epoch 259/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.7256 - val_loss: 3.1324\n",
            "Epoch 260/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.7169 - val_loss: 3.1204\n",
            "Epoch 261/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.7083 - val_loss: 3.1088\n",
            "Epoch 262/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.7000 - val_loss: 3.0973\n",
            "Epoch 263/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.6920 - val_loss: 3.0860\n",
            "Epoch 264/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.6844 - val_loss: 3.0755\n",
            "Epoch 265/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.6768 - val_loss: 3.0659\n",
            "Epoch 266/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.6693 - val_loss: 3.0564\n",
            "Epoch 267/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.6620 - val_loss: 3.0470\n",
            "Epoch 268/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.6547 - val_loss: 3.0377\n",
            "Epoch 269/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.6474 - val_loss: 3.0285\n",
            "Epoch 270/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6403 - val_loss: 3.0194\n",
            "Epoch 271/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.6331 - val_loss: 3.0103\n",
            "Epoch 272/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.6261 - val_loss: 3.0012\n",
            "Epoch 273/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.6190 - val_loss: 2.9922\n",
            "Epoch 274/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.6120 - val_loss: 2.9836\n",
            "Epoch 275/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.6050 - val_loss: 2.9754\n",
            "Epoch 276/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.5981 - val_loss: 2.9671\n",
            "Epoch 277/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.5912 - val_loss: 2.9589\n",
            "Epoch 278/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.5848 - val_loss: 2.9508\n",
            "Epoch 279/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.5786 - val_loss: 2.9428\n",
            "Epoch 280/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.5724 - val_loss: 2.9348\n",
            "Epoch 281/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.5665 - val_loss: 2.9269\n",
            "Epoch 282/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.5611 - val_loss: 2.9191\n",
            "Epoch 283/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.5557 - val_loss: 2.9115\n",
            "Epoch 284/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.5503 - val_loss: 2.9039\n",
            "Epoch 285/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.5451 - val_loss: 2.8963\n",
            "Epoch 286/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.5398 - val_loss: 2.8889\n",
            "Epoch 287/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.5346 - val_loss: 2.8815\n",
            "Epoch 288/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.5295 - val_loss: 2.8748\n",
            "Epoch 289/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.5244 - val_loss: 2.8682\n",
            "Epoch 290/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.5193 - val_loss: 2.8616\n",
            "Epoch 291/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.5142 - val_loss: 2.8551\n",
            "Epoch 292/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.5091 - val_loss: 2.8486\n",
            "Epoch 293/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.5041 - val_loss: 2.8420\n",
            "Epoch 294/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.4990 - val_loss: 2.8355\n",
            "Epoch 295/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.4940 - val_loss: 2.8290\n",
            "Epoch 296/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.4890 - val_loss: 2.8226\n",
            "Epoch 297/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.4840 - val_loss: 2.8161\n",
            "Epoch 298/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.4790 - val_loss: 2.8096\n",
            "Epoch 299/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.4740 - val_loss: 2.8031\n",
            "Epoch 300/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.4689 - val_loss: 2.7966\n",
            "Epoch 301/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.4639 - val_loss: 2.7901\n",
            "Epoch 302/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.4589 - val_loss: 2.7836\n",
            "Epoch 303/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.4539 - val_loss: 2.7770\n",
            "Epoch 304/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.4488 - val_loss: 2.7705\n",
            "Epoch 305/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.4438 - val_loss: 2.7640\n",
            "Epoch 306/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.4389 - val_loss: 2.7574\n",
            "Epoch 307/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.4341 - val_loss: 2.7515\n",
            "Epoch 308/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.4293 - val_loss: 2.7463\n",
            "Epoch 309/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.4245 - val_loss: 2.7412\n",
            "Epoch 310/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.4198 - val_loss: 2.7361\n",
            "Epoch 311/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.4154 - val_loss: 2.7311\n",
            "Epoch 312/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.4110 - val_loss: 2.7261\n",
            "Epoch 313/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.4068 - val_loss: 2.7212\n",
            "Epoch 314/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.4028 - val_loss: 2.7163\n",
            "Epoch 315/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3987 - val_loss: 2.7114\n",
            "Epoch 316/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.3947 - val_loss: 2.7066\n",
            "Epoch 317/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3907 - val_loss: 2.7019\n",
            "Epoch 318/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.3868 - val_loss: 2.6978\n",
            "Epoch 319/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3828 - val_loss: 2.6937\n",
            "Epoch 320/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.3789 - val_loss: 2.6896\n",
            "Epoch 321/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3751 - val_loss: 2.6856\n",
            "Epoch 322/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3716 - val_loss: 2.6815\n",
            "Epoch 323/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.3681 - val_loss: 2.6776\n",
            "Epoch 324/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.3646 - val_loss: 2.6736\n",
            "Epoch 325/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3612 - val_loss: 2.6697\n",
            "Epoch 326/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.3578 - val_loss: 2.6658\n",
            "Epoch 327/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.3544 - val_loss: 2.6620\n",
            "Epoch 328/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.3512 - val_loss: 2.6581\n",
            "Epoch 329/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.3482 - val_loss: 2.6546\n",
            "Epoch 330/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3454 - val_loss: 2.6513\n",
            "Epoch 331/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3426 - val_loss: 2.6481\n",
            "Epoch 332/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3400 - val_loss: 2.6449\n",
            "Epoch 333/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.3375 - val_loss: 2.6418\n",
            "Epoch 334/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.3351 - val_loss: 2.6387\n",
            "Epoch 335/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.3327 - val_loss: 2.6357\n",
            "Epoch 336/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3303 - val_loss: 2.6327\n",
            "Epoch 337/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3279 - val_loss: 2.6298\n",
            "Epoch 338/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.3256 - val_loss: 2.6268\n",
            "Epoch 339/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.3233 - val_loss: 2.6240\n",
            "Epoch 340/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.3210 - val_loss: 2.6211\n",
            "Epoch 341/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.3187 - val_loss: 2.6183\n",
            "Epoch 342/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.3166 - val_loss: 2.6155\n",
            "Epoch 343/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3145 - val_loss: 2.6127\n",
            "Epoch 344/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.3125 - val_loss: 2.6100\n",
            "Epoch 345/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.3104 - val_loss: 2.6073\n",
            "Epoch 346/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.3084 - val_loss: 2.6046\n",
            "Epoch 347/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3064 - val_loss: 2.6022\n",
            "Epoch 348/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.3045 - val_loss: 2.6000\n",
            "Epoch 349/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.3028 - val_loss: 2.5978\n",
            "Epoch 350/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.3010 - val_loss: 2.5957\n",
            "Epoch 351/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.2993 - val_loss: 2.5936\n",
            "Epoch 352/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.2976 - val_loss: 2.5915\n",
            "Epoch 353/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2959 - val_loss: 2.5894\n",
            "Epoch 354/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2942 - val_loss: 2.5874\n",
            "Epoch 355/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2925 - val_loss: 2.5854\n",
            "Epoch 356/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2908 - val_loss: 2.5833\n",
            "Epoch 357/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2892 - val_loss: 2.5813\n",
            "Epoch 358/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.2875 - val_loss: 2.5793\n",
            "Epoch 359/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2859 - val_loss: 2.5773\n",
            "Epoch 360/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2842 - val_loss: 2.5754\n",
            "Epoch 361/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.2826 - val_loss: 2.5734\n",
            "Epoch 362/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2810 - val_loss: 2.5714\n",
            "Epoch 363/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2793 - val_loss: 2.5694\n",
            "Epoch 364/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.2777 - val_loss: 2.5675\n",
            "Epoch 365/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.2761 - val_loss: 2.5655\n",
            "Epoch 366/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.2744 - val_loss: 2.5636\n",
            "Epoch 367/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2729 - val_loss: 2.5616\n",
            "Epoch 368/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.2715 - val_loss: 2.5597\n",
            "Epoch 369/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.2701 - val_loss: 2.5578\n",
            "Epoch 370/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2689 - val_loss: 2.5560\n",
            "Epoch 371/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2677 - val_loss: 2.5542\n",
            "Epoch 372/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2665 - val_loss: 2.5524\n",
            "Epoch 373/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2654 - val_loss: 2.5507\n",
            "Epoch 374/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2643 - val_loss: 2.5490\n",
            "Epoch 375/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2632 - val_loss: 2.5473\n",
            "Epoch 376/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.2621 - val_loss: 2.5457\n",
            "Epoch 377/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2610 - val_loss: 2.5441\n",
            "Epoch 378/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2600 - val_loss: 2.5424\n",
            "Epoch 379/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2589 - val_loss: 2.5408\n",
            "Epoch 380/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2579 - val_loss: 2.5392\n",
            "Epoch 381/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.2568 - val_loss: 2.5377\n",
            "Epoch 382/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2558 - val_loss: 2.5363\n",
            "Epoch 383/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.2547 - val_loss: 2.5351\n",
            "Epoch 384/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2537 - val_loss: 2.5339\n",
            "Epoch 385/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.2527 - val_loss: 2.5327\n",
            "Epoch 386/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2516 - val_loss: 2.5314\n",
            "Epoch 387/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2506 - val_loss: 2.5302\n",
            "Epoch 388/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2496 - val_loss: 2.5290\n",
            "Epoch 389/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2486 - val_loss: 2.5278\n",
            "Epoch 390/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2475 - val_loss: 2.5266\n",
            "Epoch 391/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2465 - val_loss: 2.5254\n",
            "Epoch 392/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.2455 - val_loss: 2.5242\n",
            "Epoch 393/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.2445 - val_loss: 2.5230\n",
            "Epoch 394/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2435 - val_loss: 2.5218\n",
            "Epoch 395/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.2424 - val_loss: 2.5206\n",
            "Epoch 396/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.2414 - val_loss: 2.5194\n",
            "Epoch 397/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2404 - val_loss: 2.5182\n",
            "Epoch 398/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2394 - val_loss: 2.5170\n",
            "Epoch 399/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.2383 - val_loss: 2.5161\n",
            "Epoch 400/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.2373 - val_loss: 2.5151\n",
            "Epoch 401/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2363 - val_loss: 2.5142\n",
            "Epoch 402/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2353 - val_loss: 2.5132\n",
            "Epoch 403/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2342 - val_loss: 2.5123\n",
            "Epoch 404/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2332 - val_loss: 2.5113\n",
            "Epoch 405/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2322 - val_loss: 2.5103\n",
            "Epoch 406/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3.2311 - val_loss: 2.5094\n",
            "Epoch 407/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2301 - val_loss: 2.5084\n",
            "Epoch 408/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2290 - val_loss: 2.5077\n",
            "Epoch 409/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2280 - val_loss: 2.5071\n",
            "Epoch 410/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2271 - val_loss: 2.5064\n",
            "Epoch 411/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.2262 - val_loss: 2.5057\n",
            "Epoch 412/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2254 - val_loss: 2.5051\n",
            "Epoch 413/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2246 - val_loss: 2.5044\n",
            "Epoch 414/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.2238 - val_loss: 2.5038\n",
            "Epoch 415/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2231 - val_loss: 2.5032\n",
            "Epoch 416/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.2224 - val_loss: 2.5026\n",
            "Epoch 417/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2217 - val_loss: 2.5020\n",
            "Epoch 418/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2210 - val_loss: 2.5015\n",
            "Epoch 419/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.2204 - val_loss: 2.5009\n",
            "Epoch 420/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2197 - val_loss: 2.5004\n",
            "Epoch 421/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2190 - val_loss: 2.4998\n",
            "Epoch 422/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2183 - val_loss: 2.4993\n",
            "Epoch 423/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2176 - val_loss: 2.4988\n",
            "Epoch 424/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2170 - val_loss: 2.4982\n",
            "Epoch 425/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2163 - val_loss: 2.4977\n",
            "Epoch 426/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.2156 - val_loss: 2.4972\n",
            "Epoch 427/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.2150 - val_loss: 2.4967\n",
            "Epoch 428/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2143 - val_loss: 2.4962\n",
            "Epoch 429/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.2136 - val_loss: 2.4957\n",
            "Epoch 430/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.2130 - val_loss: 2.4952\n",
            "Epoch 431/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2123 - val_loss: 2.4947\n",
            "Epoch 432/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.2116 - val_loss: 2.4942\n",
            "Epoch 433/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.2110 - val_loss: 2.4937\n",
            "Epoch 434/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.2103 - val_loss: 2.4932\n",
            "Epoch 435/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.2096 - val_loss: 2.4927\n",
            "Epoch 436/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.2089 - val_loss: 2.4922\n",
            "Epoch 437/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.2083 - val_loss: 2.4917\n",
            "Epoch 438/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2076 - val_loss: 2.4912\n",
            "Epoch 439/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2069 - val_loss: 2.4907\n",
            "Epoch 440/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2063 - val_loss: 2.4902\n",
            "Epoch 441/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2056 - val_loss: 2.4898\n",
            "Epoch 442/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2049 - val_loss: 2.4893\n",
            "Epoch 443/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2042 - val_loss: 2.4888\n",
            "Epoch 444/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2036 - val_loss: 2.4883\n",
            "Epoch 445/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2029 - val_loss: 2.4878\n",
            "Epoch 446/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.2022 - val_loss: 2.4873\n",
            "Epoch 447/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2015 - val_loss: 2.4868\n",
            "Epoch 448/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2008 - val_loss: 2.4863\n",
            "Epoch 449/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.2002 - val_loss: 2.4858\n",
            "Epoch 450/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1995 - val_loss: 2.4853\n",
            "Epoch 451/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1988 - val_loss: 2.4848\n",
            "Epoch 452/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.1981 - val_loss: 2.4843\n",
            "Epoch 453/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1974 - val_loss: 2.4838\n",
            "Epoch 454/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.1967 - val_loss: 2.4834\n",
            "Epoch 455/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.1960 - val_loss: 2.4829\n",
            "Epoch 456/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.1953 - val_loss: 2.4824\n",
            "Epoch 457/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1947 - val_loss: 2.4819\n",
            "Epoch 458/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.1940 - val_loss: 2.4814\n",
            "Epoch 459/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1933 - val_loss: 2.4809\n",
            "Epoch 460/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1926 - val_loss: 2.4804\n",
            "Epoch 461/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1919 - val_loss: 2.4799\n",
            "Epoch 462/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1912 - val_loss: 2.4794\n",
            "Epoch 463/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.1905 - val_loss: 2.4789\n",
            "Epoch 464/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1898 - val_loss: 2.4783\n",
            "Epoch 465/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1891 - val_loss: 2.4778\n",
            "Epoch 466/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1884 - val_loss: 2.4773\n",
            "Epoch 467/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1877 - val_loss: 2.4768\n",
            "Epoch 468/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1870 - val_loss: 2.4763\n",
            "Epoch 469/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1863 - val_loss: 2.4758\n",
            "Epoch 470/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.1855 - val_loss: 2.4753\n",
            "Epoch 471/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.1848 - val_loss: 2.4748\n",
            "Epoch 472/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1841 - val_loss: 2.4743\n",
            "Epoch 473/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.1834 - val_loss: 2.4738\n",
            "Epoch 474/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1827 - val_loss: 2.4732\n",
            "Epoch 475/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.1820 - val_loss: 2.4727\n",
            "Epoch 476/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.1813 - val_loss: 2.4722\n",
            "Epoch 477/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1805 - val_loss: 2.4717\n",
            "Epoch 478/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.1798 - val_loss: 2.4712\n",
            "Epoch 479/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.1791 - val_loss: 2.4707\n",
            "Epoch 480/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1784 - val_loss: 2.4701\n",
            "Epoch 481/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1776 - val_loss: 2.4696\n",
            "Epoch 482/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1769 - val_loss: 2.4691\n",
            "Epoch 483/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.1762 - val_loss: 2.4685\n",
            "Epoch 484/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1755 - val_loss: 2.4680\n",
            "Epoch 485/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1747 - val_loss: 2.4675\n",
            "Epoch 486/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1740 - val_loss: 2.4669\n",
            "Epoch 487/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.1733 - val_loss: 2.4664\n",
            "Epoch 488/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1725 - val_loss: 2.4659\n",
            "Epoch 489/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1718 - val_loss: 2.4653\n",
            "Epoch 490/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1711 - val_loss: 2.4648\n",
            "Epoch 491/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1703 - val_loss: 2.4643\n",
            "Epoch 492/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1696 - val_loss: 2.4637\n",
            "Epoch 493/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.1688 - val_loss: 2.4632\n",
            "Epoch 494/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1681 - val_loss: 2.4626\n",
            "Epoch 495/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1674 - val_loss: 2.4621\n",
            "Epoch 496/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1666 - val_loss: 2.4615\n",
            "Epoch 497/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.1659 - val_loss: 2.4610\n",
            "Epoch 498/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.1651 - val_loss: 2.4605\n",
            "Epoch 499/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1644 - val_loss: 2.4599\n",
            "Epoch 500/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1637 - val_loss: 2.4594\n",
            "Epoch 501/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1630 - val_loss: 2.4589\n",
            "Epoch 502/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1623 - val_loss: 2.4583\n",
            "Epoch 503/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1616 - val_loss: 2.4578\n",
            "Epoch 504/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.1609 - val_loss: 2.4573\n",
            "Epoch 505/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1602 - val_loss: 2.4568\n",
            "Epoch 506/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1594 - val_loss: 2.4563\n",
            "Epoch 507/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1587 - val_loss: 2.4558\n",
            "Epoch 508/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.1580 - val_loss: 2.4553\n",
            "Epoch 509/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1573 - val_loss: 2.4548\n",
            "Epoch 510/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.1566 - val_loss: 2.4543\n",
            "Epoch 511/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1559 - val_loss: 2.4538\n",
            "Epoch 512/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1552 - val_loss: 2.4532\n",
            "Epoch 513/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1544 - val_loss: 2.4527\n",
            "Epoch 514/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1537 - val_loss: 2.4522\n",
            "Epoch 515/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.1530 - val_loss: 2.4517\n",
            "Epoch 516/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1523 - val_loss: 2.4512\n",
            "Epoch 517/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1516 - val_loss: 2.4507\n",
            "Epoch 518/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1509 - val_loss: 2.4502\n",
            "Epoch 519/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1501 - val_loss: 2.4497\n",
            "Epoch 520/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1494 - val_loss: 2.4492\n",
            "Epoch 521/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1487 - val_loss: 2.4487\n",
            "Epoch 522/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1480 - val_loss: 2.4482\n",
            "Epoch 523/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.1473 - val_loss: 2.4477\n",
            "Epoch 524/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.1465 - val_loss: 2.4472\n",
            "Epoch 525/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1458 - val_loss: 2.4467\n",
            "Epoch 526/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.1451 - val_loss: 2.4462\n",
            "Epoch 527/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.1444 - val_loss: 2.4457\n",
            "Epoch 528/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.1436 - val_loss: 2.4452\n",
            "Epoch 529/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1429 - val_loss: 2.4447\n",
            "Epoch 530/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.1422 - val_loss: 2.4442\n",
            "Epoch 531/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.1414 - val_loss: 2.4437\n",
            "Epoch 532/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1407 - val_loss: 2.4431\n",
            "Epoch 533/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.1400 - val_loss: 2.4426\n",
            "Epoch 534/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1392 - val_loss: 2.4421\n",
            "Epoch 535/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1385 - val_loss: 2.4416\n",
            "Epoch 536/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1378 - val_loss: 2.4411\n",
            "Epoch 537/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1370 - val_loss: 2.4406\n",
            "Epoch 538/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.1363 - val_loss: 2.4401\n",
            "Epoch 539/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1355 - val_loss: 2.4395\n",
            "Epoch 540/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1348 - val_loss: 2.4390\n",
            "Epoch 541/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1340 - val_loss: 2.4385\n",
            "Epoch 542/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1333 - val_loss: 2.4380\n",
            "Epoch 543/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1326 - val_loss: 2.4375\n",
            "Epoch 544/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1318 - val_loss: 2.4369\n",
            "Epoch 545/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1311 - val_loss: 2.4364\n",
            "Epoch 546/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1303 - val_loss: 2.4359\n",
            "Epoch 547/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1295 - val_loss: 2.4354\n",
            "Epoch 548/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.1288 - val_loss: 2.4349\n",
            "Epoch 549/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.1280 - val_loss: 2.4343\n",
            "Epoch 550/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.1273 - val_loss: 2.4338\n",
            "Epoch 551/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.1265 - val_loss: 2.4333\n",
            "Epoch 552/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.1258 - val_loss: 2.4327\n",
            "Epoch 553/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.1250 - val_loss: 2.4322\n",
            "Epoch 554/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.1242 - val_loss: 2.4317\n",
            "Epoch 555/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1235 - val_loss: 2.4311\n",
            "Epoch 556/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1227 - val_loss: 2.4306\n",
            "Epoch 557/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.1220 - val_loss: 2.4301\n",
            "Epoch 558/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1212 - val_loss: 2.4295\n",
            "Epoch 559/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1204 - val_loss: 2.4290\n",
            "Epoch 560/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1196 - val_loss: 2.4285\n",
            "Epoch 561/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1189 - val_loss: 2.4279\n",
            "Epoch 562/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1181 - val_loss: 2.4274\n",
            "Epoch 563/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.1173 - val_loss: 2.4268\n",
            "Epoch 564/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1166 - val_loss: 2.4263\n",
            "Epoch 565/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1158 - val_loss: 2.4258\n",
            "Epoch 566/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1150 - val_loss: 2.4252\n",
            "Epoch 567/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.1142 - val_loss: 2.4247\n",
            "Epoch 568/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.1135 - val_loss: 2.4242\n",
            "Epoch 569/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1128 - val_loss: 2.4236\n",
            "Epoch 570/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.1120 - val_loss: 2.4231\n",
            "Epoch 571/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.1113 - val_loss: 2.4226\n",
            "Epoch 572/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.1106 - val_loss: 2.4221\n",
            "Epoch 573/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1099 - val_loss: 2.4217\n",
            "Epoch 574/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.1091 - val_loss: 2.4212\n",
            "Epoch 575/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1084 - val_loss: 2.4207\n",
            "Epoch 576/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.1077 - val_loss: 2.4202\n",
            "Epoch 577/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.1069 - val_loss: 2.4197\n",
            "Epoch 578/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.1062 - val_loss: 2.4193\n",
            "Epoch 579/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1055 - val_loss: 2.4188\n",
            "Epoch 580/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1048 - val_loss: 2.4183\n",
            "Epoch 581/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1040 - val_loss: 2.4179\n",
            "Epoch 582/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1033 - val_loss: 2.4174\n",
            "Epoch 583/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.1026 - val_loss: 2.4169\n",
            "Epoch 584/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1018 - val_loss: 2.4165\n",
            "Epoch 585/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.1011 - val_loss: 2.4160\n",
            "Epoch 586/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.1004 - val_loss: 2.4156\n",
            "Epoch 587/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0996 - val_loss: 2.4151\n",
            "Epoch 588/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.0989 - val_loss: 2.4146\n",
            "Epoch 589/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0982 - val_loss: 2.4142\n",
            "Epoch 590/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0974 - val_loss: 2.4137\n",
            "Epoch 591/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0967 - val_loss: 2.4133\n",
            "Epoch 592/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0959 - val_loss: 2.4128\n",
            "Epoch 593/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0952 - val_loss: 2.4124\n",
            "Epoch 594/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.0945 - val_loss: 2.4119\n",
            "Epoch 595/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0937 - val_loss: 2.4114\n",
            "Epoch 596/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.0930 - val_loss: 2.4110\n",
            "Epoch 597/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.0922 - val_loss: 2.4105\n",
            "Epoch 598/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0915 - val_loss: 2.4101\n",
            "Epoch 599/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.0907 - val_loss: 2.4096\n",
            "Epoch 600/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0900 - val_loss: 2.4091\n",
            "Epoch 601/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0892 - val_loss: 2.4087\n",
            "Epoch 602/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.0885 - val_loss: 2.4082\n",
            "Epoch 603/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.0877 - val_loss: 2.4078\n",
            "Epoch 604/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0870 - val_loss: 2.4073\n",
            "Epoch 605/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0862 - val_loss: 2.4068\n",
            "Epoch 606/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0855 - val_loss: 2.4064\n",
            "Epoch 607/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0847 - val_loss: 2.4059\n",
            "Epoch 608/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0840 - val_loss: 2.4054\n",
            "Epoch 609/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.0833 - val_loss: 2.4050\n",
            "Epoch 610/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0826 - val_loss: 2.4046\n",
            "Epoch 611/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.0818 - val_loss: 2.4041\n",
            "Epoch 612/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.0811 - val_loss: 2.4037\n",
            "Epoch 613/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.0804 - val_loss: 2.4033\n",
            "Epoch 614/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0797 - val_loss: 2.4029\n",
            "Epoch 615/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0790 - val_loss: 2.4025\n",
            "Epoch 616/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0782 - val_loss: 2.4021\n",
            "Epoch 617/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0775 - val_loss: 2.4017\n",
            "Epoch 618/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.0768 - val_loss: 2.4013\n",
            "Epoch 619/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0761 - val_loss: 2.4010\n",
            "Epoch 620/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0753 - val_loss: 2.4006\n",
            "Epoch 621/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.0746 - val_loss: 2.4002\n",
            "Epoch 622/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0739 - val_loss: 2.3998\n",
            "Epoch 623/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.0732 - val_loss: 2.3994\n",
            "Epoch 624/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0724 - val_loss: 2.3991\n",
            "Epoch 625/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.0717 - val_loss: 2.3987\n",
            "Epoch 626/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0710 - val_loss: 2.3983\n",
            "Epoch 627/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0702 - val_loss: 2.3979\n",
            "Epoch 628/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0695 - val_loss: 2.3976\n",
            "Epoch 629/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.0688 - val_loss: 2.3972\n",
            "Epoch 630/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.0680 - val_loss: 2.3968\n",
            "Epoch 631/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0673 - val_loss: 2.3965\n",
            "Epoch 632/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0666 - val_loss: 2.3961\n",
            "Epoch 633/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0658 - val_loss: 2.3957\n",
            "Epoch 634/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0651 - val_loss: 2.3954\n",
            "Epoch 635/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0644 - val_loss: 2.3950\n",
            "Epoch 636/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.0636 - val_loss: 2.3946\n",
            "Epoch 637/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0629 - val_loss: 2.3943\n",
            "Epoch 638/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.0621 - val_loss: 2.3939\n",
            "Epoch 639/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0614 - val_loss: 2.3935\n",
            "Epoch 640/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0607 - val_loss: 2.3932\n",
            "Epoch 641/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0599 - val_loss: 2.3928\n",
            "Epoch 642/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.0592 - val_loss: 2.3924\n",
            "Epoch 643/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0584 - val_loss: 2.3921\n",
            "Epoch 644/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0577 - val_loss: 2.3917\n",
            "Epoch 645/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0569 - val_loss: 2.3913\n",
            "Epoch 646/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3.0562 - val_loss: 2.3910\n",
            "Epoch 647/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0554 - val_loss: 2.3906\n",
            "Epoch 648/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0547 - val_loss: 2.3902\n",
            "Epoch 649/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0540 - val_loss: 2.3898\n",
            "Epoch 650/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0532 - val_loss: 2.3895\n",
            "Epoch 651/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0525 - val_loss: 2.3891\n",
            "Epoch 652/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0517 - val_loss: 2.3887\n",
            "Epoch 653/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0509 - val_loss: 2.3884\n",
            "Epoch 654/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0502 - val_loss: 2.3880\n",
            "Epoch 655/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0494 - val_loss: 2.3876\n",
            "Epoch 656/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.0487 - val_loss: 2.3872\n",
            "Epoch 657/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.0480 - val_loss: 2.3868\n",
            "Epoch 658/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.0473 - val_loss: 2.3864\n",
            "Epoch 659/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0466 - val_loss: 2.3860\n",
            "Epoch 660/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0459 - val_loss: 2.3856\n",
            "Epoch 661/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0452 - val_loss: 2.3851\n",
            "Epoch 662/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0445 - val_loss: 2.3847\n",
            "Epoch 663/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0438 - val_loss: 2.3842\n",
            "Epoch 664/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.0431 - val_loss: 2.3838\n",
            "Epoch 665/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0424 - val_loss: 2.3833\n",
            "Epoch 666/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0417 - val_loss: 2.3829\n",
            "Epoch 667/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0410 - val_loss: 2.3824\n",
            "Epoch 668/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0403 - val_loss: 2.3819\n",
            "Epoch 669/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 3.0396 - val_loss: 2.3815\n",
            "Epoch 670/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0389 - val_loss: 2.3810\n",
            "Epoch 671/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0382 - val_loss: 2.3805\n",
            "Epoch 672/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0374 - val_loss: 2.3800\n",
            "Epoch 673/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0367 - val_loss: 2.3795\n",
            "Epoch 674/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.0360 - val_loss: 2.3790\n",
            "Epoch 675/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.0353 - val_loss: 2.3785\n",
            "Epoch 676/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0346 - val_loss: 2.3780\n",
            "Epoch 677/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0339 - val_loss: 2.3775\n",
            "Epoch 678/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0332 - val_loss: 2.3770\n",
            "Epoch 679/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0325 - val_loss: 2.3765\n",
            "Epoch 680/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0317 - val_loss: 2.3760\n",
            "Epoch 681/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0310 - val_loss: 2.3755\n",
            "Epoch 682/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0303 - val_loss: 2.3750\n",
            "Epoch 683/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0296 - val_loss: 2.3745\n",
            "Epoch 684/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0289 - val_loss: 2.3740\n",
            "Epoch 685/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.0281 - val_loss: 2.3735\n",
            "Epoch 686/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0274 - val_loss: 2.3730\n",
            "Epoch 687/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.0267 - val_loss: 2.3725\n",
            "Epoch 688/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0260 - val_loss: 2.3720\n",
            "Epoch 689/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0253 - val_loss: 2.3714\n",
            "Epoch 690/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0245 - val_loss: 2.3709\n",
            "Epoch 691/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3.0238 - val_loss: 2.3704\n",
            "Epoch 692/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.0231 - val_loss: 2.3699\n",
            "Epoch 693/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0223 - val_loss: 2.3694\n",
            "Epoch 694/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.0216 - val_loss: 2.3688\n",
            "Epoch 695/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0209 - val_loss: 2.3683\n",
            "Epoch 696/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0201 - val_loss: 2.3678\n",
            "Epoch 697/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0194 - val_loss: 2.3673\n",
            "Epoch 698/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.0187 - val_loss: 2.3667\n",
            "Epoch 699/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0179 - val_loss: 2.3662\n",
            "Epoch 700/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0172 - val_loss: 2.3657\n",
            "Epoch 701/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.0165 - val_loss: 2.3651\n",
            "Epoch 702/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.0157 - val_loss: 2.3646\n",
            "Epoch 703/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.0150 - val_loss: 2.3641\n",
            "Epoch 704/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0142 - val_loss: 2.3635\n",
            "Epoch 705/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0135 - val_loss: 2.3630\n",
            "Epoch 706/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0127 - val_loss: 2.3625\n",
            "Epoch 707/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0120 - val_loss: 2.3619\n",
            "Epoch 708/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0112 - val_loss: 2.3614\n",
            "Epoch 709/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0105 - val_loss: 2.3608\n",
            "Epoch 710/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.0097 - val_loss: 2.3603\n",
            "Epoch 711/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0090 - val_loss: 2.3598\n",
            "Epoch 712/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0082 - val_loss: 2.3592\n",
            "Epoch 713/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.0075 - val_loss: 2.3587\n",
            "Epoch 714/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.0067 - val_loss: 2.3581\n",
            "Epoch 715/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0060 - val_loss: 2.3576\n",
            "Epoch 716/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0052 - val_loss: 2.3570\n",
            "Epoch 717/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0045 - val_loss: 2.3565\n",
            "Epoch 718/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.0037 - val_loss: 2.3559\n",
            "Epoch 719/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0029 - val_loss: 2.3554\n",
            "Epoch 720/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.0022 - val_loss: 2.3548\n",
            "Epoch 721/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.0014 - val_loss: 2.3543\n",
            "Epoch 722/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0007 - val_loss: 2.3537\n",
            "Epoch 723/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9999 - val_loss: 2.3532\n",
            "Epoch 724/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9991 - val_loss: 2.3526\n",
            "Epoch 725/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9984 - val_loss: 2.3521\n",
            "Epoch 726/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9976 - val_loss: 2.3515\n",
            "Epoch 727/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9968 - val_loss: 2.3509\n",
            "Epoch 728/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9960 - val_loss: 2.3504\n",
            "Epoch 729/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9953 - val_loss: 2.3498\n",
            "Epoch 730/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9945 - val_loss: 2.3493\n",
            "Epoch 731/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.9937 - val_loss: 2.3487\n",
            "Epoch 732/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9929 - val_loss: 2.3481\n",
            "Epoch 733/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9922 - val_loss: 2.3476\n",
            "Epoch 734/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9914 - val_loss: 2.3470\n",
            "Epoch 735/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9906 - val_loss: 2.3464\n",
            "Epoch 736/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9898 - val_loss: 2.3459\n",
            "Epoch 737/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.9891 - val_loss: 2.3453\n",
            "Epoch 738/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9884 - val_loss: 2.3448\n",
            "Epoch 739/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9877 - val_loss: 2.3443\n",
            "Epoch 740/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9870 - val_loss: 2.3437\n",
            "Epoch 741/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9864 - val_loss: 2.3432\n",
            "Epoch 742/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9857 - val_loss: 2.3427\n",
            "Epoch 743/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9851 - val_loss: 2.3422\n",
            "Epoch 744/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9845 - val_loss: 2.3417\n",
            "Epoch 745/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9839 - val_loss: 2.3413\n",
            "Epoch 746/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.9832 - val_loss: 2.3408\n",
            "Epoch 747/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9826 - val_loss: 2.3403\n",
            "Epoch 748/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.9820 - val_loss: 2.3398\n",
            "Epoch 749/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9814 - val_loss: 2.3393\n",
            "Epoch 750/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9808 - val_loss: 2.3388\n",
            "Epoch 751/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9802 - val_loss: 2.3383\n",
            "Epoch 752/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9796 - val_loss: 2.3379\n",
            "Epoch 753/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9790 - val_loss: 2.3374\n",
            "Epoch 754/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9784 - val_loss: 2.3369\n",
            "Epoch 755/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9778 - val_loss: 2.3364\n",
            "Epoch 756/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9772 - val_loss: 2.3360\n",
            "Epoch 757/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.9767 - val_loss: 2.3355\n",
            "Epoch 758/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9761 - val_loss: 2.3351\n",
            "Epoch 759/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9755 - val_loss: 2.3346\n",
            "Epoch 760/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9749 - val_loss: 2.3342\n",
            "Epoch 761/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9743 - val_loss: 2.3338\n",
            "Epoch 762/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.9737 - val_loss: 2.3334\n",
            "Epoch 763/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9731 - val_loss: 2.3330\n",
            "Epoch 764/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9725 - val_loss: 2.3326\n",
            "Epoch 765/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.9719 - val_loss: 2.3322\n",
            "Epoch 766/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9714 - val_loss: 2.3318\n",
            "Epoch 767/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9708 - val_loss: 2.3314\n",
            "Epoch 768/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9702 - val_loss: 2.3310\n",
            "Epoch 769/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9696 - val_loss: 2.3306\n",
            "Epoch 770/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9690 - val_loss: 2.3301\n",
            "Epoch 771/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9684 - val_loss: 2.3297\n",
            "Epoch 772/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9678 - val_loss: 2.3293\n",
            "Epoch 773/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9672 - val_loss: 2.3288\n",
            "Epoch 774/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9667 - val_loss: 2.3284\n",
            "Epoch 775/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9661 - val_loss: 2.3280\n",
            "Epoch 776/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9655 - val_loss: 2.3276\n",
            "Epoch 777/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9650 - val_loss: 2.3272\n",
            "Epoch 778/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9644 - val_loss: 2.3267\n",
            "Epoch 779/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9639 - val_loss: 2.3263\n",
            "Epoch 780/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9634 - val_loss: 2.3259\n",
            "Epoch 781/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9629 - val_loss: 2.3254\n",
            "Epoch 782/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.9624 - val_loss: 2.3250\n",
            "Epoch 783/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9619 - val_loss: 2.3246\n",
            "Epoch 784/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9613 - val_loss: 2.3241\n",
            "Epoch 785/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9608 - val_loss: 2.3237\n",
            "Epoch 786/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.9603 - val_loss: 2.3232\n",
            "Epoch 787/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9598 - val_loss: 2.3228\n",
            "Epoch 788/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9593 - val_loss: 2.3224\n",
            "Epoch 789/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9588 - val_loss: 2.3219\n",
            "Epoch 790/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9583 - val_loss: 2.3215\n",
            "Epoch 791/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.9578 - val_loss: 2.3210\n",
            "Epoch 792/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9573 - val_loss: 2.3205\n",
            "Epoch 793/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9568 - val_loss: 2.3201\n",
            "Epoch 794/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.9563 - val_loss: 2.3196\n",
            "Epoch 795/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9558 - val_loss: 2.3192\n",
            "Epoch 796/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9553 - val_loss: 2.3187\n",
            "Epoch 797/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9548 - val_loss: 2.3183\n",
            "Epoch 798/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9543 - val_loss: 2.3178\n",
            "Epoch 799/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.9537 - val_loss: 2.3173\n",
            "Epoch 800/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.9532 - val_loss: 2.3169\n",
            "Epoch 801/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9527 - val_loss: 2.3164\n",
            "Epoch 802/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9522 - val_loss: 2.3159\n",
            "Epoch 803/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9517 - val_loss: 2.3155\n",
            "Epoch 804/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9512 - val_loss: 2.3150\n",
            "Epoch 805/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9507 - val_loss: 2.3145\n",
            "Epoch 806/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9502 - val_loss: 2.3141\n",
            "Epoch 807/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.9497 - val_loss: 2.3136\n",
            "Epoch 808/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.9492 - val_loss: 2.3131\n",
            "Epoch 809/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.9487 - val_loss: 2.3126\n",
            "Epoch 810/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9481 - val_loss: 2.3122\n",
            "Epoch 811/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.9476 - val_loss: 2.3117\n",
            "Epoch 812/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9471 - val_loss: 2.3112\n",
            "Epoch 813/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.9466 - val_loss: 2.3108\n",
            "Epoch 814/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9461 - val_loss: 2.3104\n",
            "Epoch 815/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9456 - val_loss: 2.3099\n",
            "Epoch 816/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9451 - val_loss: 2.3095\n",
            "Epoch 817/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9446 - val_loss: 2.3091\n",
            "Epoch 818/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9440 - val_loss: 2.3087\n",
            "Epoch 819/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9435 - val_loss: 2.3083\n",
            "Epoch 820/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9430 - val_loss: 2.3078\n",
            "Epoch 821/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9425 - val_loss: 2.3074\n",
            "Epoch 822/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9420 - val_loss: 2.3069\n",
            "Epoch 823/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9415 - val_loss: 2.3065\n",
            "Epoch 824/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9409 - val_loss: 2.3060\n",
            "Epoch 825/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9404 - val_loss: 2.3056\n",
            "Epoch 826/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9399 - val_loss: 2.3051\n",
            "Epoch 827/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9394 - val_loss: 2.3046\n",
            "Epoch 828/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9389 - val_loss: 2.3042\n",
            "Epoch 829/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9383 - val_loss: 2.3038\n",
            "Epoch 830/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9378 - val_loss: 2.3033\n",
            "Epoch 831/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9373 - val_loss: 2.3029\n",
            "Epoch 832/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9368 - val_loss: 2.3024\n",
            "Epoch 833/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9362 - val_loss: 2.3020\n",
            "Epoch 834/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9358 - val_loss: 2.3016\n",
            "Epoch 835/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9353 - val_loss: 2.3012\n",
            "Epoch 836/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9348 - val_loss: 2.3008\n",
            "Epoch 837/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9343 - val_loss: 2.3004\n",
            "Epoch 838/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9339 - val_loss: 2.3000\n",
            "Epoch 839/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9334 - val_loss: 2.2996\n",
            "Epoch 840/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9329 - val_loss: 2.2993\n",
            "Epoch 841/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9325 - val_loss: 2.2989\n",
            "Epoch 842/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9320 - val_loss: 2.2986\n",
            "Epoch 843/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9315 - val_loss: 2.2983\n",
            "Epoch 844/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9311 - val_loss: 2.2980\n",
            "Epoch 845/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9306 - val_loss: 2.2976\n",
            "Epoch 846/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9301 - val_loss: 2.2973\n",
            "Epoch 847/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9297 - val_loss: 2.2970\n",
            "Epoch 848/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9292 - val_loss: 2.2967\n",
            "Epoch 849/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9287 - val_loss: 2.2964\n",
            "Epoch 850/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9283 - val_loss: 2.2961\n",
            "Epoch 851/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9278 - val_loss: 2.2958\n",
            "Epoch 852/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9273 - val_loss: 2.2955\n",
            "Epoch 853/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9268 - val_loss: 2.2952\n",
            "Epoch 854/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9264 - val_loss: 2.2950\n",
            "Epoch 855/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9259 - val_loss: 2.2947\n",
            "Epoch 856/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.9254 - val_loss: 2.2944\n",
            "Epoch 857/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9250 - val_loss: 2.2941\n",
            "Epoch 858/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.9245 - val_loss: 2.2938\n",
            "Epoch 859/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9240 - val_loss: 2.2935\n",
            "Epoch 860/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9236 - val_loss: 2.2933\n",
            "Epoch 861/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9231 - val_loss: 2.2930\n",
            "Epoch 862/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9226 - val_loss: 2.2927\n",
            "Epoch 863/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9221 - val_loss: 2.2924\n",
            "Epoch 864/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9217 - val_loss: 2.2921\n",
            "Epoch 865/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9212 - val_loss: 2.2919\n",
            "Epoch 866/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.9207 - val_loss: 2.2916\n",
            "Epoch 867/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9202 - val_loss: 2.2913\n",
            "Epoch 868/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9198 - val_loss: 2.2910\n",
            "Epoch 869/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9193 - val_loss: 2.2908\n",
            "Epoch 870/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9188 - val_loss: 2.2905\n",
            "Epoch 871/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9183 - val_loss: 2.2902\n",
            "Epoch 872/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9179 - val_loss: 2.2899\n",
            "Epoch 873/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9174 - val_loss: 2.2896\n",
            "Epoch 874/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9169 - val_loss: 2.2893\n",
            "Epoch 875/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9165 - val_loss: 2.2889\n",
            "Epoch 876/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9160 - val_loss: 2.2886\n",
            "Epoch 877/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9156 - val_loss: 2.2882\n",
            "Epoch 878/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9151 - val_loss: 2.2878\n",
            "Epoch 879/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.9146 - val_loss: 2.2875\n",
            "Epoch 880/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9142 - val_loss: 2.2871\n",
            "Epoch 881/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9137 - val_loss: 2.2867\n",
            "Epoch 882/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9133 - val_loss: 2.2863\n",
            "Epoch 883/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9129 - val_loss: 2.2859\n",
            "Epoch 884/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.9124 - val_loss: 2.2854\n",
            "Epoch 885/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9120 - val_loss: 2.2850\n",
            "Epoch 886/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9116 - val_loss: 2.2845\n",
            "Epoch 887/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9112 - val_loss: 2.2840\n",
            "Epoch 888/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9107 - val_loss: 2.2836\n",
            "Epoch 889/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9103 - val_loss: 2.2831\n",
            "Epoch 890/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.9099 - val_loss: 2.2826\n",
            "Epoch 891/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9095 - val_loss: 2.2822\n",
            "Epoch 892/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9091 - val_loss: 2.2817\n",
            "Epoch 893/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9087 - val_loss: 2.2813\n",
            "Epoch 894/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9083 - val_loss: 2.2808\n",
            "Epoch 895/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9079 - val_loss: 2.2804\n",
            "Epoch 896/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9075 - val_loss: 2.2799\n",
            "Epoch 897/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9071 - val_loss: 2.2795\n",
            "Epoch 898/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9067 - val_loss: 2.2791\n",
            "Epoch 899/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.9063 - val_loss: 2.2787\n",
            "Epoch 900/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9059 - val_loss: 2.2782\n",
            "Epoch 901/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.9055 - val_loss: 2.2778\n",
            "Epoch 902/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.9051 - val_loss: 2.2774\n",
            "Epoch 903/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9048 - val_loss: 2.2770\n",
            "Epoch 904/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.9044 - val_loss: 2.2766\n",
            "Epoch 905/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9040 - val_loss: 2.2762\n",
            "Epoch 906/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.9036 - val_loss: 2.2758\n",
            "Epoch 907/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9032 - val_loss: 2.2753\n",
            "Epoch 908/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9028 - val_loss: 2.2749\n",
            "Epoch 909/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.9024 - val_loss: 2.2745\n",
            "Epoch 910/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9020 - val_loss: 2.2741\n",
            "Epoch 911/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9016 - val_loss: 2.2737\n",
            "Epoch 912/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9012 - val_loss: 2.2733\n",
            "Epoch 913/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.9008 - val_loss: 2.2729\n",
            "Epoch 914/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9004 - val_loss: 2.2725\n",
            "Epoch 915/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.9000 - val_loss: 2.2721\n",
            "Epoch 916/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8997 - val_loss: 2.2717\n",
            "Epoch 917/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8993 - val_loss: 2.2714\n",
            "Epoch 918/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8989 - val_loss: 2.2710\n",
            "Epoch 919/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8986 - val_loss: 2.2707\n",
            "Epoch 920/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8982 - val_loss: 2.2704\n",
            "Epoch 921/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8978 - val_loss: 2.2701\n",
            "Epoch 922/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8975 - val_loss: 2.2698\n",
            "Epoch 923/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.8971 - val_loss: 2.2695\n",
            "Epoch 924/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8967 - val_loss: 2.2692\n",
            "Epoch 925/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8963 - val_loss: 2.2690\n",
            "Epoch 926/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8960 - val_loss: 2.2687\n",
            "Epoch 927/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8956 - val_loss: 2.2684\n",
            "Epoch 928/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8952 - val_loss: 2.2682\n",
            "Epoch 929/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8949 - val_loss: 2.2679\n",
            "Epoch 930/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8945 - val_loss: 2.2677\n",
            "Epoch 931/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8941 - val_loss: 2.2674\n",
            "Epoch 932/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8937 - val_loss: 2.2672\n",
            "Epoch 933/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8934 - val_loss: 2.2670\n",
            "Epoch 934/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8930 - val_loss: 2.2667\n",
            "Epoch 935/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8926 - val_loss: 2.2665\n",
            "Epoch 936/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8922 - val_loss: 2.2663\n",
            "Epoch 937/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8919 - val_loss: 2.2661\n",
            "Epoch 938/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8915 - val_loss: 2.2658\n",
            "Epoch 939/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8911 - val_loss: 2.2656\n",
            "Epoch 940/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8908 - val_loss: 2.2653\n",
            "Epoch 941/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8904 - val_loss: 2.2650\n",
            "Epoch 942/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8901 - val_loss: 2.2647\n",
            "Epoch 943/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8897 - val_loss: 2.2644\n",
            "Epoch 944/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8894 - val_loss: 2.2641\n",
            "Epoch 945/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8890 - val_loss: 2.2638\n",
            "Epoch 946/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8886 - val_loss: 2.2634\n",
            "Epoch 947/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8883 - val_loss: 2.2631\n",
            "Epoch 948/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8879 - val_loss: 2.2627\n",
            "Epoch 949/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8876 - val_loss: 2.2624\n",
            "Epoch 950/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8872 - val_loss: 2.2620\n",
            "Epoch 951/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8868 - val_loss: 2.2617\n",
            "Epoch 952/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8865 - val_loss: 2.2613\n",
            "Epoch 953/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.8861 - val_loss: 2.2609\n",
            "Epoch 954/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8858 - val_loss: 2.2606\n",
            "Epoch 955/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8854 - val_loss: 2.2602\n",
            "Epoch 956/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8850 - val_loss: 2.2598\n",
            "Epoch 957/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8847 - val_loss: 2.2594\n",
            "Epoch 958/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8843 - val_loss: 2.2590\n",
            "Epoch 959/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8839 - val_loss: 2.2587\n",
            "Epoch 960/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8836 - val_loss: 2.2583\n",
            "Epoch 961/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8832 - val_loss: 2.2579\n",
            "Epoch 962/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8828 - val_loss: 2.2575\n",
            "Epoch 963/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8825 - val_loss: 2.2571\n",
            "Epoch 964/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8821 - val_loss: 2.2567\n",
            "Epoch 965/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8817 - val_loss: 2.2563\n",
            "Epoch 966/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8813 - val_loss: 2.2559\n",
            "Epoch 967/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8810 - val_loss: 2.2555\n",
            "Epoch 968/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8806 - val_loss: 2.2551\n",
            "Epoch 969/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8802 - val_loss: 2.2548\n",
            "Epoch 970/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8799 - val_loss: 2.2545\n",
            "Epoch 971/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.8795 - val_loss: 2.2541\n",
            "Epoch 972/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.8791 - val_loss: 2.2538\n",
            "Epoch 973/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8788 - val_loss: 2.2535\n",
            "Epoch 974/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8784 - val_loss: 2.2531\n",
            "Epoch 975/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8780 - val_loss: 2.2528\n",
            "Epoch 976/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8776 - val_loss: 2.2524\n",
            "Epoch 977/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8773 - val_loss: 2.2521\n",
            "Epoch 978/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8769 - val_loss: 2.2517\n",
            "Epoch 979/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.8765 - val_loss: 2.2513\n",
            "Epoch 980/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8762 - val_loss: 2.2510\n",
            "Epoch 981/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8758 - val_loss: 2.2506\n",
            "Epoch 982/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8754 - val_loss: 2.2502\n",
            "Epoch 983/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8750 - val_loss: 2.2498\n",
            "Epoch 984/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.8746 - val_loss: 2.2494\n",
            "Epoch 985/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8743 - val_loss: 2.2491\n",
            "Epoch 986/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8739 - val_loss: 2.2487\n",
            "Epoch 987/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.8735 - val_loss: 2.2484\n",
            "Epoch 988/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.8731 - val_loss: 2.2480\n",
            "Epoch 989/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8728 - val_loss: 2.2477\n",
            "Epoch 990/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8724 - val_loss: 2.2473\n",
            "Epoch 991/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8720 - val_loss: 2.2470\n",
            "Epoch 992/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.8716 - val_loss: 2.2466\n",
            "Epoch 993/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8713 - val_loss: 2.2462\n",
            "Epoch 994/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8709 - val_loss: 2.2458\n",
            "Epoch 995/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8705 - val_loss: 2.2454\n",
            "Epoch 996/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8701 - val_loss: 2.2450\n",
            "Epoch 997/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8698 - val_loss: 2.2446\n",
            "Epoch 998/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8694 - val_loss: 2.2442\n",
            "Epoch 999/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.8690 - val_loss: 2.2438\n",
            "Epoch 1000/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8687 - val_loss: 2.2434\n",
            "Epoch 1001/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8683 - val_loss: 2.2430\n",
            "Epoch 1002/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8679 - val_loss: 2.2426\n",
            "Epoch 1003/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8675 - val_loss: 2.2422\n",
            "Epoch 1004/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8672 - val_loss: 2.2419\n",
            "Epoch 1005/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8668 - val_loss: 2.2415\n",
            "Epoch 1006/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8664 - val_loss: 2.2411\n",
            "Epoch 1007/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8660 - val_loss: 2.2407\n",
            "Epoch 1008/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8657 - val_loss: 2.2403\n",
            "Epoch 1009/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8653 - val_loss: 2.2399\n",
            "Epoch 1010/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.8649 - val_loss: 2.2395\n",
            "Epoch 1011/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8645 - val_loss: 2.2392\n",
            "Epoch 1012/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8642 - val_loss: 2.2388\n",
            "Epoch 1013/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8638 - val_loss: 2.2384\n",
            "Epoch 1014/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8634 - val_loss: 2.2380\n",
            "Epoch 1015/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.8630 - val_loss: 2.2376\n",
            "Epoch 1016/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8627 - val_loss: 2.2372\n",
            "Epoch 1017/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8623 - val_loss: 2.2368\n",
            "Epoch 1018/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8619 - val_loss: 2.2364\n",
            "Epoch 1019/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8615 - val_loss: 2.2361\n",
            "Epoch 1020/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8611 - val_loss: 2.2357\n",
            "Epoch 1021/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8608 - val_loss: 2.2353\n",
            "Epoch 1022/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8604 - val_loss: 2.2349\n",
            "Epoch 1023/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8600 - val_loss: 2.2345\n",
            "Epoch 1024/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.8596 - val_loss: 2.2341\n",
            "Epoch 1025/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8592 - val_loss: 2.2337\n",
            "Epoch 1026/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.8588 - val_loss: 2.2333\n",
            "Epoch 1027/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.8585 - val_loss: 2.2329\n",
            "Epoch 1028/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8581 - val_loss: 2.2325\n",
            "Epoch 1029/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8577 - val_loss: 2.2321\n",
            "Epoch 1030/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8573 - val_loss: 2.2317\n",
            "Epoch 1031/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8569 - val_loss: 2.2313\n",
            "Epoch 1032/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.8565 - val_loss: 2.2309\n",
            "Epoch 1033/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8561 - val_loss: 2.2306\n",
            "Epoch 1034/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8558 - val_loss: 2.2302\n",
            "Epoch 1035/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8554 - val_loss: 2.2298\n",
            "Epoch 1036/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8550 - val_loss: 2.2294\n",
            "Epoch 1037/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.8546 - val_loss: 2.2290\n",
            "Epoch 1038/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8542 - val_loss: 2.2286\n",
            "Epoch 1039/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8538 - val_loss: 2.2282\n",
            "Epoch 1040/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8534 - val_loss: 2.2278\n",
            "Epoch 1041/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8530 - val_loss: 2.2274\n",
            "Epoch 1042/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8526 - val_loss: 2.2270\n",
            "Epoch 1043/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8522 - val_loss: 2.2265\n",
            "Epoch 1044/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8518 - val_loss: 2.2261\n",
            "Epoch 1045/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8515 - val_loss: 2.2257\n",
            "Epoch 1046/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8511 - val_loss: 2.2253\n",
            "Epoch 1047/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8507 - val_loss: 2.2249\n",
            "Epoch 1048/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8503 - val_loss: 2.2245\n",
            "Epoch 1049/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8499 - val_loss: 2.2241\n",
            "Epoch 1050/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8495 - val_loss: 2.2237\n",
            "Epoch 1051/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8491 - val_loss: 2.2233\n",
            "Epoch 1052/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.8487 - val_loss: 2.2229\n",
            "Epoch 1053/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8483 - val_loss: 2.2225\n",
            "Epoch 1054/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8479 - val_loss: 2.2221\n",
            "Epoch 1055/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8475 - val_loss: 2.2217\n",
            "Epoch 1056/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8471 - val_loss: 2.2212\n",
            "Epoch 1057/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8467 - val_loss: 2.2208\n",
            "Epoch 1058/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8463 - val_loss: 2.2204\n",
            "Epoch 1059/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8459 - val_loss: 2.2200\n",
            "Epoch 1060/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8455 - val_loss: 2.2196\n",
            "Epoch 1061/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8451 - val_loss: 2.2192\n",
            "Epoch 1062/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8447 - val_loss: 2.2188\n",
            "Epoch 1063/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8443 - val_loss: 2.2183\n",
            "Epoch 1064/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.8439 - val_loss: 2.2179\n",
            "Epoch 1065/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8435 - val_loss: 2.2175\n",
            "Epoch 1066/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.8431 - val_loss: 2.2171\n",
            "Epoch 1067/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8427 - val_loss: 2.2167\n",
            "Epoch 1068/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8423 - val_loss: 2.2163\n",
            "Epoch 1069/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8419 - val_loss: 2.2158\n",
            "Epoch 1070/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8414 - val_loss: 2.2154\n",
            "Epoch 1071/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8410 - val_loss: 2.2150\n",
            "Epoch 1072/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8406 - val_loss: 2.2146\n",
            "Epoch 1073/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8402 - val_loss: 2.2141\n",
            "Epoch 1074/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8398 - val_loss: 2.2137\n",
            "Epoch 1075/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8394 - val_loss: 2.2133\n",
            "Epoch 1076/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.8390 - val_loss: 2.2129\n",
            "Epoch 1077/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8386 - val_loss: 2.2125\n",
            "Epoch 1078/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8382 - val_loss: 2.2122\n",
            "Epoch 1079/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8378 - val_loss: 2.2119\n",
            "Epoch 1080/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8374 - val_loss: 2.2117\n",
            "Epoch 1081/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.8369 - val_loss: 2.2114\n",
            "Epoch 1082/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.8365 - val_loss: 2.2111\n",
            "Epoch 1083/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8361 - val_loss: 2.2108\n",
            "Epoch 1084/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8357 - val_loss: 2.2105\n",
            "Epoch 1085/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.8353 - val_loss: 2.2102\n",
            "Epoch 1086/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8349 - val_loss: 2.2099\n",
            "Epoch 1087/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8344 - val_loss: 2.2096\n",
            "Epoch 1088/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8340 - val_loss: 2.2094\n",
            "Epoch 1089/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8336 - val_loss: 2.2091\n",
            "Epoch 1090/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8332 - val_loss: 2.2088\n",
            "Epoch 1091/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8328 - val_loss: 2.2085\n",
            "Epoch 1092/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8324 - val_loss: 2.2082\n",
            "Epoch 1093/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8319 - val_loss: 2.2079\n",
            "Epoch 1094/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8315 - val_loss: 2.2076\n",
            "Epoch 1095/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8311 - val_loss: 2.2073\n",
            "Epoch 1096/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8307 - val_loss: 2.2070\n",
            "Epoch 1097/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8303 - val_loss: 2.2067\n",
            "Epoch 1098/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8298 - val_loss: 2.2064\n",
            "Epoch 1099/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8294 - val_loss: 2.2061\n",
            "Epoch 1100/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8290 - val_loss: 2.2058\n",
            "Epoch 1101/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8286 - val_loss: 2.2055\n",
            "Epoch 1102/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.8281 - val_loss: 2.2053\n",
            "Epoch 1103/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8277 - val_loss: 2.2050\n",
            "Epoch 1104/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8273 - val_loss: 2.2047\n",
            "Epoch 1105/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8269 - val_loss: 2.2044\n",
            "Epoch 1106/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.8264 - val_loss: 2.2041\n",
            "Epoch 1107/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.8260 - val_loss: 2.2038\n",
            "Epoch 1108/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.8256 - val_loss: 2.2035\n",
            "Epoch 1109/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8251 - val_loss: 2.2032\n",
            "Epoch 1110/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8247 - val_loss: 2.2029\n",
            "Epoch 1111/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.8243 - val_loss: 2.2026\n",
            "Epoch 1112/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8239 - val_loss: 2.2023\n",
            "Epoch 1113/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8234 - val_loss: 2.2020\n",
            "Epoch 1114/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8230 - val_loss: 2.2017\n",
            "Epoch 1115/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8226 - val_loss: 2.2014\n",
            "Epoch 1116/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8221 - val_loss: 2.2011\n",
            "Epoch 1117/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8217 - val_loss: 2.2008\n",
            "Epoch 1118/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8213 - val_loss: 2.2005\n",
            "Epoch 1119/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8208 - val_loss: 2.2002\n",
            "Epoch 1120/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8204 - val_loss: 2.1999\n",
            "Epoch 1121/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8200 - val_loss: 2.1995\n",
            "Epoch 1122/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8195 - val_loss: 2.1992\n",
            "Epoch 1123/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8191 - val_loss: 2.1989\n",
            "Epoch 1124/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.8186 - val_loss: 2.1986\n",
            "Epoch 1125/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.8182 - val_loss: 2.1983\n",
            "Epoch 1126/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8178 - val_loss: 2.1980\n",
            "Epoch 1127/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8173 - val_loss: 2.1977\n",
            "Epoch 1128/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8169 - val_loss: 2.1974\n",
            "Epoch 1129/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8164 - val_loss: 2.1971\n",
            "Epoch 1130/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8160 - val_loss: 2.1968\n",
            "Epoch 1131/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8156 - val_loss: 2.1965\n",
            "Epoch 1132/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.8151 - val_loss: 2.1962\n",
            "Epoch 1133/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8147 - val_loss: 2.1959\n",
            "Epoch 1134/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8142 - val_loss: 2.1955\n",
            "Epoch 1135/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8138 - val_loss: 2.1952\n",
            "Epoch 1136/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8133 - val_loss: 2.1949\n",
            "Epoch 1137/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8129 - val_loss: 2.1946\n",
            "Epoch 1138/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8124 - val_loss: 2.1943\n",
            "Epoch 1139/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8120 - val_loss: 2.1940\n",
            "Epoch 1140/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8116 - val_loss: 2.1937\n",
            "Epoch 1141/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8111 - val_loss: 2.1934\n",
            "Epoch 1142/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8107 - val_loss: 2.1930\n",
            "Epoch 1143/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.8102 - val_loss: 2.1927\n",
            "Epoch 1144/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8098 - val_loss: 2.1924\n",
            "Epoch 1145/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8093 - val_loss: 2.1921\n",
            "Epoch 1146/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8089 - val_loss: 2.1918\n",
            "Epoch 1147/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8084 - val_loss: 2.1915\n",
            "Epoch 1148/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8079 - val_loss: 2.1911\n",
            "Epoch 1149/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8075 - val_loss: 2.1908\n",
            "Epoch 1150/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.8070 - val_loss: 2.1905\n",
            "Epoch 1151/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.8066 - val_loss: 2.1902\n",
            "Epoch 1152/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.8061 - val_loss: 2.1899\n",
            "Epoch 1153/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.8057 - val_loss: 2.1896\n",
            "Epoch 1154/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8052 - val_loss: 2.1892\n",
            "Epoch 1155/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8048 - val_loss: 2.1889\n",
            "Epoch 1156/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8043 - val_loss: 2.1886\n",
            "Epoch 1157/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.8038 - val_loss: 2.1883\n",
            "Epoch 1158/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8034 - val_loss: 2.1879\n",
            "Epoch 1159/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8029 - val_loss: 2.1876\n",
            "Epoch 1160/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8025 - val_loss: 2.1873\n",
            "Epoch 1161/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8020 - val_loss: 2.1870\n",
            "Epoch 1162/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8015 - val_loss: 2.1867\n",
            "Epoch 1163/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8011 - val_loss: 2.1863\n",
            "Epoch 1164/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8006 - val_loss: 2.1860\n",
            "Epoch 1165/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8001 - val_loss: 2.1857\n",
            "Epoch 1166/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7997 - val_loss: 2.1854\n",
            "Epoch 1167/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7992 - val_loss: 2.1850\n",
            "Epoch 1168/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7988 - val_loss: 2.1847\n",
            "Epoch 1169/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7983 - val_loss: 2.1844\n",
            "Epoch 1170/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7978 - val_loss: 2.1840\n",
            "Epoch 1171/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7974 - val_loss: 2.1837\n",
            "Epoch 1172/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7969 - val_loss: 2.1834\n",
            "Epoch 1173/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7964 - val_loss: 2.1831\n",
            "Epoch 1174/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.7959 - val_loss: 2.1827\n",
            "Epoch 1175/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.7955 - val_loss: 2.1824\n",
            "Epoch 1176/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.7950 - val_loss: 2.1821\n",
            "Epoch 1177/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7945 - val_loss: 2.1817\n",
            "Epoch 1178/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7941 - val_loss: 2.1814\n",
            "Epoch 1179/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7936 - val_loss: 2.1811\n",
            "Epoch 1180/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7931 - val_loss: 2.1807\n",
            "Epoch 1181/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7926 - val_loss: 2.1804\n",
            "Epoch 1182/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7922 - val_loss: 2.1801\n",
            "Epoch 1183/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7917 - val_loss: 2.1797\n",
            "Epoch 1184/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7912 - val_loss: 2.1794\n",
            "Epoch 1185/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7907 - val_loss: 2.1791\n",
            "Epoch 1186/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7902 - val_loss: 2.1787\n",
            "Epoch 1187/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7898 - val_loss: 2.1784\n",
            "Epoch 1188/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7893 - val_loss: 2.1780\n",
            "Epoch 1189/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7888 - val_loss: 2.1777\n",
            "Epoch 1190/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.7883 - val_loss: 2.1774\n",
            "Epoch 1191/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7878 - val_loss: 2.1770\n",
            "Epoch 1192/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7874 - val_loss: 2.1767\n",
            "Epoch 1193/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7869 - val_loss: 2.1764\n",
            "Epoch 1194/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7864 - val_loss: 2.1761\n",
            "Epoch 1195/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7859 - val_loss: 2.1758\n",
            "Epoch 1196/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7855 - val_loss: 2.1755\n",
            "Epoch 1197/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7850 - val_loss: 2.1752\n",
            "Epoch 1198/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7845 - val_loss: 2.1749\n",
            "Epoch 1199/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7840 - val_loss: 2.1746\n",
            "Epoch 1200/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7835 - val_loss: 2.1743\n",
            "Epoch 1201/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7831 - val_loss: 2.1740\n",
            "Epoch 1202/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7826 - val_loss: 2.1737\n",
            "Epoch 1203/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7821 - val_loss: 2.1734\n",
            "Epoch 1204/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7816 - val_loss: 2.1731\n",
            "Epoch 1205/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7811 - val_loss: 2.1728\n",
            "Epoch 1206/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7806 - val_loss: 2.1724\n",
            "Epoch 1207/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7801 - val_loss: 2.1721\n",
            "Epoch 1208/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7797 - val_loss: 2.1718\n",
            "Epoch 1209/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7792 - val_loss: 2.1715\n",
            "Epoch 1210/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7787 - val_loss: 2.1712\n",
            "Epoch 1211/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7782 - val_loss: 2.1709\n",
            "Epoch 1212/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7777 - val_loss: 2.1706\n",
            "Epoch 1213/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7772 - val_loss: 2.1703\n",
            "Epoch 1214/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7767 - val_loss: 2.1700\n",
            "Epoch 1215/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7762 - val_loss: 2.1697\n",
            "Epoch 1216/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7758 - val_loss: 2.1694\n",
            "Epoch 1217/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7753 - val_loss: 2.1691\n",
            "Epoch 1218/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7748 - val_loss: 2.1687\n",
            "Epoch 1219/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7743 - val_loss: 2.1684\n",
            "Epoch 1220/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7738 - val_loss: 2.1681\n",
            "Epoch 1221/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7733 - val_loss: 2.1678\n",
            "Epoch 1222/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7728 - val_loss: 2.1675\n",
            "Epoch 1223/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7723 - val_loss: 2.1672\n",
            "Epoch 1224/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7718 - val_loss: 2.1669\n",
            "Epoch 1225/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7713 - val_loss: 2.1666\n",
            "Epoch 1226/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7708 - val_loss: 2.1662\n",
            "Epoch 1227/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7703 - val_loss: 2.1659\n",
            "Epoch 1228/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7698 - val_loss: 2.1656\n",
            "Epoch 1229/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7693 - val_loss: 2.1653\n",
            "Epoch 1230/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7689 - val_loss: 2.1650\n",
            "Epoch 1231/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7684 - val_loss: 2.1646\n",
            "Epoch 1232/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7679 - val_loss: 2.1643\n",
            "Epoch 1233/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7674 - val_loss: 2.1640\n",
            "Epoch 1234/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7670 - val_loss: 2.1637\n",
            "Epoch 1235/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7665 - val_loss: 2.1633\n",
            "Epoch 1236/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7660 - val_loss: 2.1630\n",
            "Epoch 1237/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.7656 - val_loss: 2.1628\n",
            "Epoch 1238/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7651 - val_loss: 2.1625\n",
            "Epoch 1239/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7646 - val_loss: 2.1622\n",
            "Epoch 1240/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7641 - val_loss: 2.1620\n",
            "Epoch 1241/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7637 - val_loss: 2.1617\n",
            "Epoch 1242/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7632 - val_loss: 2.1614\n",
            "Epoch 1243/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7627 - val_loss: 2.1611\n",
            "Epoch 1244/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7623 - val_loss: 2.1609\n",
            "Epoch 1245/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7618 - val_loss: 2.1606\n",
            "Epoch 1246/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7613 - val_loss: 2.1603\n",
            "Epoch 1247/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7608 - val_loss: 2.1601\n",
            "Epoch 1248/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7604 - val_loss: 2.1598\n",
            "Epoch 1249/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7599 - val_loss: 2.1595\n",
            "Epoch 1250/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7594 - val_loss: 2.1593\n",
            "Epoch 1251/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7590 - val_loss: 2.1590\n",
            "Epoch 1252/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7585 - val_loss: 2.1587\n",
            "Epoch 1253/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7580 - val_loss: 2.1585\n",
            "Epoch 1254/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7575 - val_loss: 2.1582\n",
            "Epoch 1255/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7570 - val_loss: 2.1579\n",
            "Epoch 1256/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7566 - val_loss: 2.1576\n",
            "Epoch 1257/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7561 - val_loss: 2.1574\n",
            "Epoch 1258/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7557 - val_loss: 2.1571\n",
            "Epoch 1259/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7552 - val_loss: 2.1568\n",
            "Epoch 1260/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7548 - val_loss: 2.1565\n",
            "Epoch 1261/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7543 - val_loss: 2.1563\n",
            "Epoch 1262/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7539 - val_loss: 2.1560\n",
            "Epoch 1263/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7535 - val_loss: 2.1557\n",
            "Epoch 1264/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7530 - val_loss: 2.1554\n",
            "Epoch 1265/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7526 - val_loss: 2.1552\n",
            "Epoch 1266/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7522 - val_loss: 2.1549\n",
            "Epoch 1267/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7518 - val_loss: 2.1546\n",
            "Epoch 1268/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7514 - val_loss: 2.1544\n",
            "Epoch 1269/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7509 - val_loss: 2.1541\n",
            "Epoch 1270/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.7505 - val_loss: 2.1538\n",
            "Epoch 1271/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.7501 - val_loss: 2.1535\n",
            "Epoch 1272/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7497 - val_loss: 2.1533\n",
            "Epoch 1273/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7493 - val_loss: 2.1530\n",
            "Epoch 1274/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7488 - val_loss: 2.1527\n",
            "Epoch 1275/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7484 - val_loss: 2.1524\n",
            "Epoch 1276/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7480 - val_loss: 2.1522\n",
            "Epoch 1277/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7476 - val_loss: 2.1519\n",
            "Epoch 1278/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7472 - val_loss: 2.1516\n",
            "Epoch 1279/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7467 - val_loss: 2.1513\n",
            "Epoch 1280/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7463 - val_loss: 2.1511\n",
            "Epoch 1281/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7459 - val_loss: 2.1508\n",
            "Epoch 1282/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7455 - val_loss: 2.1505\n",
            "Epoch 1283/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7451 - val_loss: 2.1502\n",
            "Epoch 1284/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7446 - val_loss: 2.1500\n",
            "Epoch 1285/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7442 - val_loss: 2.1497\n",
            "Epoch 1286/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7438 - val_loss: 2.1494\n",
            "Epoch 1287/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7434 - val_loss: 2.1491\n",
            "Epoch 1288/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7429 - val_loss: 2.1489\n",
            "Epoch 1289/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7425 - val_loss: 2.1486\n",
            "Epoch 1290/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7421 - val_loss: 2.1483\n",
            "Epoch 1291/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7417 - val_loss: 2.1480\n",
            "Epoch 1292/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7413 - val_loss: 2.1477\n",
            "Epoch 1293/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7408 - val_loss: 2.1475\n",
            "Epoch 1294/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7404 - val_loss: 2.1472\n",
            "Epoch 1295/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7400 - val_loss: 2.1469\n",
            "Epoch 1296/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7396 - val_loss: 2.1466\n",
            "Epoch 1297/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7391 - val_loss: 2.1464\n",
            "Epoch 1298/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7387 - val_loss: 2.1461\n",
            "Epoch 1299/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7383 - val_loss: 2.1458\n",
            "Epoch 1300/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7378 - val_loss: 2.1455\n",
            "Epoch 1301/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7374 - val_loss: 2.1452\n",
            "Epoch 1302/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7370 - val_loss: 2.1449\n",
            "Epoch 1303/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7366 - val_loss: 2.1447\n",
            "Epoch 1304/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7361 - val_loss: 2.1444\n",
            "Epoch 1305/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7357 - val_loss: 2.1441\n",
            "Epoch 1306/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7353 - val_loss: 2.1438\n",
            "Epoch 1307/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7348 - val_loss: 2.1435\n",
            "Epoch 1308/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7344 - val_loss: 2.1432\n",
            "Epoch 1309/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7340 - val_loss: 2.1430\n",
            "Epoch 1310/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7335 - val_loss: 2.1427\n",
            "Epoch 1311/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7331 - val_loss: 2.1424\n",
            "Epoch 1312/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7327 - val_loss: 2.1421\n",
            "Epoch 1313/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7322 - val_loss: 2.1418\n",
            "Epoch 1314/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7318 - val_loss: 2.1415\n",
            "Epoch 1315/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7314 - val_loss: 2.1412\n",
            "Epoch 1316/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7309 - val_loss: 2.1410\n",
            "Epoch 1317/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7305 - val_loss: 2.1407\n",
            "Epoch 1318/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7300 - val_loss: 2.1404\n",
            "Epoch 1319/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.7296 - val_loss: 2.1401\n",
            "Epoch 1320/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7292 - val_loss: 2.1398\n",
            "Epoch 1321/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7287 - val_loss: 2.1395\n",
            "Epoch 1322/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7283 - val_loss: 2.1392\n",
            "Epoch 1323/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7278 - val_loss: 2.1389\n",
            "Epoch 1324/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7274 - val_loss: 2.1386\n",
            "Epoch 1325/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7270 - val_loss: 2.1383\n",
            "Epoch 1326/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7265 - val_loss: 2.1381\n",
            "Epoch 1327/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.7261 - val_loss: 2.1378\n",
            "Epoch 1328/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7256 - val_loss: 2.1375\n",
            "Epoch 1329/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7252 - val_loss: 2.1372\n",
            "Epoch 1330/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7247 - val_loss: 2.1369\n",
            "Epoch 1331/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7243 - val_loss: 2.1366\n",
            "Epoch 1332/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7238 - val_loss: 2.1363\n",
            "Epoch 1333/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7234 - val_loss: 2.1360\n",
            "Epoch 1334/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7231 - val_loss: 2.1357\n",
            "Epoch 1335/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7227 - val_loss: 2.1355\n",
            "Epoch 1336/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7223 - val_loss: 2.1352\n",
            "Epoch 1337/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7219 - val_loss: 2.1349\n",
            "Epoch 1338/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7216 - val_loss: 2.1347\n",
            "Epoch 1339/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7212 - val_loss: 2.1344\n",
            "Epoch 1340/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7208 - val_loss: 2.1341\n",
            "Epoch 1341/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7205 - val_loss: 2.1339\n",
            "Epoch 1342/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.7201 - val_loss: 2.1336\n",
            "Epoch 1343/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7197 - val_loss: 2.1334\n",
            "Epoch 1344/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7193 - val_loss: 2.1331\n",
            "Epoch 1345/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7189 - val_loss: 2.1329\n",
            "Epoch 1346/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7186 - val_loss: 2.1327\n",
            "Epoch 1347/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7182 - val_loss: 2.1324\n",
            "Epoch 1348/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7178 - val_loss: 2.1322\n",
            "Epoch 1349/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7174 - val_loss: 2.1319\n",
            "Epoch 1350/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7170 - val_loss: 2.1317\n",
            "Epoch 1351/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7167 - val_loss: 2.1315\n",
            "Epoch 1352/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7163 - val_loss: 2.1312\n",
            "Epoch 1353/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7159 - val_loss: 2.1310\n",
            "Epoch 1354/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.7155 - val_loss: 2.1307\n",
            "Epoch 1355/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7152 - val_loss: 2.1305\n",
            "Epoch 1356/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7148 - val_loss: 2.1303\n",
            "Epoch 1357/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7145 - val_loss: 2.1300\n",
            "Epoch 1358/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7142 - val_loss: 2.1298\n",
            "Epoch 1359/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7139 - val_loss: 2.1295\n",
            "Epoch 1360/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7135 - val_loss: 2.1293\n",
            "Epoch 1361/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7132 - val_loss: 2.1290\n",
            "Epoch 1362/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7129 - val_loss: 2.1288\n",
            "Epoch 1363/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7125 - val_loss: 2.1286\n",
            "Epoch 1364/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.7122 - val_loss: 2.1283\n",
            "Epoch 1365/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.7119 - val_loss: 2.1281\n",
            "Epoch 1366/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7115 - val_loss: 2.1278\n",
            "Epoch 1367/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7112 - val_loss: 2.1276\n",
            "Epoch 1368/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7109 - val_loss: 2.1273\n",
            "Epoch 1369/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.7105 - val_loss: 2.1271\n",
            "Epoch 1370/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7102 - val_loss: 2.1269\n",
            "Epoch 1371/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7099 - val_loss: 2.1268\n",
            "Epoch 1372/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7095 - val_loss: 2.1266\n",
            "Epoch 1373/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7092 - val_loss: 2.1264\n",
            "Epoch 1374/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.7089 - val_loss: 2.1263\n",
            "Epoch 1375/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7085 - val_loss: 2.1261\n",
            "Epoch 1376/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7082 - val_loss: 2.1259\n",
            "Epoch 1377/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.7079 - val_loss: 2.1258\n",
            "Epoch 1378/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7075 - val_loss: 2.1256\n",
            "Epoch 1379/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7072 - val_loss: 2.1254\n",
            "Epoch 1380/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7068 - val_loss: 2.1252\n",
            "Epoch 1381/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7065 - val_loss: 2.1251\n",
            "Epoch 1382/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7062 - val_loss: 2.1249\n",
            "Epoch 1383/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7058 - val_loss: 2.1247\n",
            "Epoch 1384/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7055 - val_loss: 2.1245\n",
            "Epoch 1385/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7052 - val_loss: 2.1244\n",
            "Epoch 1386/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.7049 - val_loss: 2.1243\n",
            "Epoch 1387/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.7046 - val_loss: 2.1242\n",
            "Epoch 1388/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7043 - val_loss: 2.1241\n",
            "Epoch 1389/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7040 - val_loss: 2.1240\n",
            "Epoch 1390/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.7037 - val_loss: 2.1240\n",
            "Epoch 1391/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7034 - val_loss: 2.1239\n",
            "Epoch 1392/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7031 - val_loss: 2.1239\n",
            "Epoch 1393/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7028 - val_loss: 2.1239\n",
            "Epoch 1394/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7025 - val_loss: 2.1238\n",
            "Epoch 1395/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7022 - val_loss: 2.1238\n",
            "Epoch 1396/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7018 - val_loss: 2.1238\n",
            "Epoch 1397/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7015 - val_loss: 2.1238\n",
            "Epoch 1398/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7012 - val_loss: 2.1239\n",
            "Epoch 1399/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7009 - val_loss: 2.1242\n",
            "Epoch 1400/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7006 - val_loss: 2.1244\n",
            "Epoch 1401/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.7003 - val_loss: 2.1247\n",
            "Epoch 1402/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7000 - val_loss: 2.1250\n",
            "Epoch 1403/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6996 - val_loss: 2.1253\n",
            "Epoch 1404/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6993 - val_loss: 2.1256\n",
            "Epoch 1405/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6990 - val_loss: 2.1259\n",
            "Epoch 1406/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6987 - val_loss: 2.1262\n",
            "Epoch 1407/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6984 - val_loss: 2.1265\n",
            "Epoch 1407: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3946ef3e10>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "losses.plot()"
      ],
      "metadata": {
        "id": "x57BoeDbrqOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "c0e21fc8-fdec-46ba-ea1a-727b8528faaf"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3946daf510>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction Years"
      ],
      "metadata": {
        "id": "hD2TjFm4i_uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2005 = model.predict(test2005)\n",
        "predictions2020 = model.predict(test2020)\n",
        "predictions1999 = model.predict(test1999)"
      ],
      "metadata": {
        "id": "hGkPg1rFrwaS"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2005"
      ],
      "metadata": {
        "id": "C3qJsfe7utXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1746a11d-9384-48f1-a6a7-7e3867c26868"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15.76254]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2020"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzK61NkZhYT2",
        "outputId": "554a8223-9e36-4824-ce0b-7ca0b18bb2c6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14.41252]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions1999"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ketVPCIpiRXS",
        "outputId": "f32e0a76-78bc-45cd-8b90-80e80e89d764"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13.30053]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    }
  ]
}